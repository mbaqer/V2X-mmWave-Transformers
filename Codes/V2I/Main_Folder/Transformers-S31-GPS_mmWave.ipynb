{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8dcf62-03c1-42ab-9ed6-a4fa1ab8d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfomers - Scenario 31 - 64 Beams - GPS!\n",
    "\n",
    "# Average Top-1 accuracy 0.07977207977207977\n",
    "# Average Top-3 accuracy 0.1794871794871795\n",
    "# Average Top-5 accuracy 0.27635327635327633\n",
    "# Average Top-7 accuracy 0.37037037037037035\n",
    "# Average Top-9 accuracy 0.443019943019943\n",
    "# Average Top-11 accuracy 0.49145299145299143\n",
    "# Average Top-13 accuracy 0.5754985754985755\n",
    "# Average Top-15 accuracy 0.6182336182336182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160fc01b-1bed-4872-93c1-d780473d516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import datetime\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch as t\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.cuda as cuda\n",
    "import torch.optim as optimizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transf\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94177f6c-d38e-4828-ae84-8042153270f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Create save directory\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd31995-0b39-47eb-b51d-2535de29cb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07-25-2024\n",
      "16_45\n"
     ]
    }
   ],
   "source": [
    "# year month day \n",
    "dayTime = datetime.datetime.now().strftime('%m-%d-%Y')\n",
    "# Minutes and seconds \n",
    "hourTime = datetime.datetime.now().strftime('%H_%M')\n",
    "print(dayTime + '\\n' + hourTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24eb053-3fe1-454f-9cfa-4644d6f35dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baqer\\Desktop\\V2X_CNN_All\\Scenario31_64-Beams\\Main_Folder//saved_folder//07-25-2024_16_45\n"
     ]
    }
   ],
   "source": [
    "pwd = os.getcwd() + '//' + 'saved_folder' + '//' + dayTime + '_' + hourTime \n",
    "print(pwd)\n",
    "# Determine whether the folder already exists\n",
    "isExists = os.path.exists(pwd)\n",
    "if not isExists:\n",
    "    os.makedirs(pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c7f6d59-1c34-4482-8072-2916ba6eaba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Baqer\\\\Desktop\\\\V2X_CNN_All\\\\Scenario31_64-Beams\\\\Main_Folder//saved_folder//07-25-2024_16_45\\\\scenario31_64_pos_beam_test.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the training files to the saved directory\n",
    "shutil.copy('./scenario31_64_pos_beam_train.csv', pwd)\n",
    "shutil.copy('./scenario31_64_pos_beam_val.csv', pwd)\n",
    "shutil.copy('./scenario31_64_pos_beam_test.csv', pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3579b0e-dc12-477d-88ff-62fb96803150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder to save analysis files and checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eff5935-f683-4a0f-bc42-126c2cde53bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = pwd + '//' + 'saved_analysis_files'\n",
    "checkpoint_directory = pwd + '//' + 'checkpoint'\n",
    "\n",
    "isExists = os.path.exists(save_directory)\n",
    "if not isExists:\n",
    "    os.makedirs(save_directory) \n",
    "        \n",
    "isExists = os.path.exists(checkpoint_directory)\n",
    "if not isExists:\n",
    "    os.makedirs(checkpoint_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0bb698-f628-4836-a68c-556484486afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Data Feeding: Create data sample list\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0382b04-811c-4912-a418-9df85dab10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFeed(Dataset):\n",
    "    def __init__(self, root_dir, nat_sort=False, transform=None, init_shuffle=True):\n",
    "        self.root = root_dir\n",
    "        self.samples = self.create_samples(self.root, shuffle=init_shuffle, nat_sort=nat_sort)\n",
    "        self.transform = transform\n",
    "\n",
    "    def create_samples(self, root, shuffle=False, nat_sort=False):\n",
    "        f = pd.read_csv(root)\n",
    "        data_samples = []\n",
    "        for idx, row in f.iterrows():\n",
    "            data = list(row.values[1:])\n",
    "            data_samples.append(data)\n",
    "        return data_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        pos_val = sample[:1]\n",
    "        pos_val = ast.literal_eval(pos_val[0])\n",
    "        pos_val = np.asarray(pos_val)\n",
    "        pos_centers = sample[1:2]\n",
    "        pos_centers = np.asarray(pos_centers)\n",
    "        return torch.tensor(pos_val, dtype=torch.float32), torch.tensor(pos_centers, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddacecf7-6da8-4d4d-8f65-a759c3d9f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Training, Testing, and Validation!\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53b7b3-30e5-4819-83c2-a4b80b096c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ab916a-a336-4d11-92fd-505d18e7f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optimizer\n",
    "import ast\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_features, num_output, d_model=512, nhead=8, num_encoder_layers=6):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(num_features, d_model)\n",
    "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers)\n",
    "        self.fc = nn.Linear(d_model, num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).unsqueeze(0)  # Add batch dimension\n",
    "        transformer_output = self.transformer(x, x)\n",
    "        output = self.fc(transformer_output.squeeze(0))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2c02a-8046-4b3d-89e8-de751f48b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10dcbbba-d52f-47df-9a15-c57f833d1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Hyper-parameters\n",
    "batch_size = 128\n",
    "val_batch_size = 1\n",
    "lr = 0.01\n",
    "decay = 1e-4\n",
    "num_epochs = 20\n",
    "train_size = [1]\n",
    "\n",
    "# Hyperparameters for our network\n",
    "input_size = 2\n",
    "node = 512\n",
    "output_size = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a1923e-e00d-4d1f-bb3a-fb8505c96773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size is 1\n",
      "Epoch No. 1\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.964011821302413\n",
      "Average Top-1 accuracy 0.04232049453162149\n",
      "Average Top-3 accuracy 0.14503090822634332\n",
      "Average Top-5 accuracy 0.2686638135996196\n",
      "Average Top-7 accuracy 0.34236804564907275\n",
      "Average Top-9 accuracy 0.44079885877318115\n",
      "Average Top-11 accuracy 0.4950071326676177\n",
      "Average Top-13 accuracy 0.5611031859248692\n",
      "Average Top-15 accuracy 0.6058012363290537\n",
      "Current accuracy: 0.04232049453162149\n",
      "Best accuracy: 0\n",
      "Saving the best model\n",
      "Updated best accuracy: 0.04232049453162149\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 2\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.7527275394951225\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.1745126010461246\n",
      "Average Top-5 accuracy 0.2719923918212078\n",
      "Average Top-7 accuracy 0.3594864479315264\n",
      "Average Top-9 accuracy 0.42605801236329055\n",
      "Average Top-11 accuracy 0.47979077508321444\n",
      "Average Top-13 accuracy 0.557774607703281\n",
      "Average Top-15 accuracy 0.5972420351878269\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.04232049453162149\n",
      "Saving the best model\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 3\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.6943350334820497\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.16310033285782216\n",
      "Average Top-5 accuracy 0.24108416547788872\n",
      "Average Top-7 accuracy 0.33523537803138376\n",
      "Average Top-9 accuracy 0.4222539229671897\n",
      "Average Top-11 accuracy 0.4888254873989539\n",
      "Average Top-13 accuracy 0.567284831193533\n",
      "Average Top-15 accuracy 0.6390870185449358\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 4\n",
      "Training-Batch No.100\n",
      "Loss = 3.7468490600585938\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.6663766780241978\n",
      "Average Top-1 accuracy 0.060865430337612936\n",
      "Average Top-3 accuracy 0.16690442225392296\n",
      "Average Top-5 accuracy 0.28007608178792204\n",
      "Average Top-7 accuracy 0.3609129814550642\n",
      "Average Top-9 accuracy 0.43366619115549215\n",
      "Average Top-11 accuracy 0.5116500237755587\n",
      "Average Top-13 accuracy 0.5877318116975749\n",
      "Average Top-15 accuracy 0.62339514978602\n",
      "Current accuracy: 0.060865430337612936\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 5\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.6538689074151245\n",
      "Average Top-1 accuracy 0.060865430337612936\n",
      "Average Top-3 accuracy 0.16690442225392296\n",
      "Average Top-5 accuracy 0.2805515929624346\n",
      "Average Top-7 accuracy 0.3613884926295768\n",
      "Average Top-9 accuracy 0.43366619115549215\n",
      "Average Top-11 accuracy 0.5116500237755587\n",
      "Average Top-13 accuracy 0.5877318116975749\n",
      "Average Top-15 accuracy 0.6319543509272468\n",
      "Current accuracy: 0.060865430337612936\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 6\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.6492575286288402\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.1745126010461246\n",
      "Average Top-5 accuracy 0.2805515929624346\n",
      "Average Top-7 accuracy 0.3613884926295768\n",
      "Average Top-9 accuracy 0.43699476937708037\n",
      "Average Top-11 accuracy 0.514978601997147\n",
      "Average Top-13 accuracy 0.5782215882073228\n",
      "Average Top-15 accuracy 0.6319543509272468\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 7\n",
      "Training-Batch No.200\n",
      "Loss = 3.6141114234924316\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.651769607904918\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.1745126010461246\n",
      "Average Top-5 accuracy 0.25962910128388017\n",
      "Average Top-7 accuracy 0.3613884926295768\n",
      "Average Top-9 accuracy 0.43699476937708037\n",
      "Average Top-11 accuracy 0.514978601997147\n",
      "Average Top-13 accuracy 0.5782215882073228\n",
      "Average Top-15 accuracy 0.6319543509272468\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 8\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.649368124919679\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.1887779362815026\n",
      "Average Top-5 accuracy 0.2805515929624346\n",
      "Average Top-7 accuracy 0.3613884926295768\n",
      "Average Top-9 accuracy 0.43699476937708037\n",
      "Average Top-11 accuracy 0.514978601997147\n",
      "Average Top-13 accuracy 0.5877318116975749\n",
      "Average Top-15 accuracy 0.6319543509272468\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 9\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.643379371051725\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.1887779362815026\n",
      "Average Top-5 accuracy 0.29053732762719925\n",
      "Average Top-7 accuracy 0.3775558725630052\n",
      "Average Top-9 accuracy 0.4484070375653828\n",
      "Average Top-11 accuracy 0.514978601997147\n",
      "Average Top-13 accuracy 0.5877318116975749\n",
      "Average Top-15 accuracy 0.6319543509272468\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 10\n",
      "Training-Batch No.300\n",
      "Loss = 3.744968891143799\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.65401176299813\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.18164526866381359\n",
      "Average Top-5 accuracy 0.29053732762719925\n",
      "Average Top-7 accuracy 0.3780313837375178\n",
      "Average Top-9 accuracy 0.4427009034712316\n",
      "Average Top-11 accuracy 0.514978601997147\n",
      "Average Top-13 accuracy 0.5877318116975749\n",
      "Average Top-15 accuracy 0.6319543509272468\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 11\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.6505367213977955\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.18164526866381359\n",
      "Average Top-5 accuracy 0.28007608178792204\n",
      "Average Top-7 accuracy 0.3775558725630052\n",
      "Average Top-9 accuracy 0.4484070375653828\n",
      "Average Top-11 accuracy 0.5211602472658108\n",
      "Average Top-13 accuracy 0.5877318116975749\n",
      "Average Top-15 accuracy 0.6390870185449358\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 12\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.6667258242907774\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.1887779362815026\n",
      "Average Top-5 accuracy 0.29053732762719925\n",
      "Average Top-7 accuracy 0.3747028055159296\n",
      "Average Top-9 accuracy 0.4484070375653828\n",
      "Average Top-11 accuracy 0.514978601997147\n",
      "Average Top-13 accuracy 0.5877318116975749\n",
      "Average Top-15 accuracy 0.6405135520684736\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 13\n",
      "Training-Batch No.400\n",
      "Loss = 3.6231653690338135\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.656600684933701\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.18164526866381359\n",
      "Average Top-5 accuracy 0.2834046600095102\n",
      "Average Top-7 accuracy 0.3775558725630052\n",
      "Average Top-9 accuracy 0.444602948169282\n",
      "Average Top-11 accuracy 0.5154541131716596\n",
      "Average Top-13 accuracy 0.5877318116975749\n",
      "Average Top-15 accuracy 0.6390870185449358\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 14\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.6496367632520808\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.1887779362815026\n",
      "Average Top-5 accuracy 0.29053732762719925\n",
      "Average Top-7 accuracy 0.3747028055159296\n",
      "Average Top-9 accuracy 0.4560152163575844\n",
      "Average Top-11 accuracy 0.514978601997147\n",
      "Average Top-13 accuracy 0.5877318116975749\n",
      "Average Top-15 accuracy 0.6405135520684736\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 15\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.6604653984038986\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.1887779362815026\n",
      "Average Top-5 accuracy 0.29053732762719925\n",
      "Average Top-7 accuracy 0.3747028055159296\n",
      "Average Top-9 accuracy 0.4484070375653828\n",
      "Average Top-11 accuracy 0.5206847360912982\n",
      "Average Top-13 accuracy 0.5877318116975749\n",
      "Average Top-15 accuracy 0.6390870185449358\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 16\n",
      "Training-Batch No.500\n",
      "Loss = 3.6691784858703613\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.63100848263692\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.1887779362815026\n",
      "Average Top-5 accuracy 0.29053732762719925\n",
      "Average Top-7 accuracy 0.3775558725630052\n",
      "Average Top-9 accuracy 0.4560152163575844\n",
      "Average Top-11 accuracy 0.5287684260580123\n",
      "Average Top-13 accuracy 0.5877318116975749\n",
      "Average Top-15 accuracy 0.6405135520684736\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 17\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.6298175411342273\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.1887779362815026\n",
      "Average Top-5 accuracy 0.29053732762719925\n",
      "Average Top-7 accuracy 0.3775558725630052\n",
      "Average Top-9 accuracy 0.4560152163575844\n",
      "Average Top-11 accuracy 0.5287684260580123\n",
      "Average Top-13 accuracy 0.5877318116975749\n",
      "Average Top-15 accuracy 0.6405135520684736\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 18\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.6297274109753777\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.1887779362815026\n",
      "Average Top-5 accuracy 0.29053732762719925\n",
      "Average Top-7 accuracy 0.3775558725630052\n",
      "Average Top-9 accuracy 0.4560152163575844\n",
      "Average Top-11 accuracy 0.5287684260580123\n",
      "Average Top-13 accuracy 0.5877318116975749\n",
      "Average Top-15 accuracy 0.6405135520684736\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 19\n",
      "Training-Batch No.600\n",
      "Loss = 3.6233057975769043\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.629661358032009\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.1887779362815026\n",
      "Average Top-5 accuracy 0.29053732762719925\n",
      "Average Top-7 accuracy 0.3775558725630052\n",
      "Average Top-9 accuracy 0.4560152163575844\n",
      "Average Top-11 accuracy 0.5287684260580123\n",
      "Average Top-13 accuracy 0.5877318116975749\n",
      "Average Top-15 accuracy 0.6405135520684736\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 20\n",
      "Start Validation\n",
      "Total validation examples: 2103\n",
      "Validation Loss: 3.630097943490537\n",
      "Average Top-1 accuracy 0.07132667617689016\n",
      "Average Top-3 accuracy 0.1887779362815026\n",
      "Average Top-5 accuracy 0.29053732762719925\n",
      "Average Top-7 accuracy 0.3775558725630052\n",
      "Average Top-9 accuracy 0.4560152163575844\n",
      "Average Top-11 accuracy 0.5287684260580123\n",
      "Average Top-13 accuracy 0.5877318116975749\n",
      "Average Top-15 accuracy 0.6405135520684736\n",
      "Current accuracy: 0.07132667617689016\n",
      "Best accuracy: 0.07132667617689016\n",
      "Updated best accuracy: 0.07132667617689016\n",
      "Saving the predicted values in a CSV file\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'scenario31_64_pos_beam_train.csv'\n",
    "val_dir = 'scenario31_64_pos_beam_val.csv'\n",
    "\n",
    "train_loader = DataLoader(DataFeed(train_dir),\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False)\n",
    "val_loader = DataLoader(DataFeed(val_dir),\n",
    "                        batch_size=val_batch_size,\n",
    "                        shuffle=False)\n",
    "\n",
    "class TransformerBeamPred(nn.Module):\n",
    "    def __init__(self, num_features, num_output):\n",
    "        super(TransformerBeamPred, self).__init__()\n",
    "        self.transformer = TransformerModel(num_features, num_output)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.transformer(inputs)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TransformerBeamPred(input_size, num_output=output_size).to(device)\n",
    "val_acc = []\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    top_1 = np.zeros((1, len(train_size)))\n",
    "    top_3 = np.zeros((1, len(train_size)))\n",
    "    top_5 = np.zeros((1, len(train_size)))\n",
    "    top_7 = np.zeros((1, len(train_size)))\n",
    "    top_9 = np.zeros((1, len(train_size)))\n",
    "    top_11 = np.zeros((1, len(train_size)))\n",
    "    top_13 = np.zeros((1, len(train_size)))\n",
    "    top_15 = np.zeros((1, len(train_size)))\n",
    "    acc_loss = 0\n",
    "    itr = []\n",
    "\n",
    "    for idx, n in enumerate(train_size):\n",
    "        print('Training size is {}'.format(n))\n",
    "        net = model\n",
    "        layers = list(net.children())\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        opt = optimizer.Adam(net.parameters(), lr=lr, weight_decay=decay)\n",
    "        LR_sch = optimizer.lr_scheduler.MultiStepLR(opt, [15, 25, 40], gamma=0.1, last_epoch=-1)\n",
    "\n",
    "        count = 0\n",
    "        running_loss = []\n",
    "        running_top1_acc = []\n",
    "        running_top3_acc = []\n",
    "        running_top5_acc = []\n",
    "        running_top7_acc = []\n",
    "        running_top9_acc = []\n",
    "        running_top11_acc = []\n",
    "        running_top13_acc = []\n",
    "        running_top15_acc = []\n",
    "        best_accuracy = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print('Epoch No. ' + str(epoch + 1))\n",
    "            skipped_batches = 0\n",
    "            net.train()\n",
    "            for tr_count, (pos_data, beam_val) in enumerate(train_loader):\n",
    "                data = pos_data.to(device)\n",
    "                label = beam_val[:, 0].to(device)\n",
    "                opt.zero_grad()\n",
    "                out = net(data)\n",
    "                loss = criterion(out, label)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                batch_loss = loss.item()\n",
    "                acc_loss += batch_loss\n",
    "                count += 1\n",
    "                if count % 100 == 0:\n",
    "                    print('Training-Batch No.' + str(count))\n",
    "                    running_loss.append(batch_loss)\n",
    "                    itr.append(count)\n",
    "                    print('Loss = ' + str(running_loss[-1]))\n",
    "\n",
    "            print('Start Validation')\n",
    "            ave_top1_acc = 0\n",
    "            ave_top3_acc = 0\n",
    "            ave_top5_acc = 0\n",
    "            ave_top7_acc = 0\n",
    "            ave_top9_acc = 0\n",
    "            ave_top11_acc = 0\n",
    "            ave_top13_acc = 0\n",
    "            ave_top15_acc = 0\n",
    "\n",
    "            ind_ten = torch.as_tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], device='cuda:0')\n",
    "\n",
    "            top1_pred_out = []\n",
    "            top3_pred_out = []\n",
    "            top5_pred_out = []\n",
    "            top7_pred_out = []\n",
    "            top9_pred_out = []\n",
    "            top11_pred_out = []\n",
    "            top13_pred_out = []\n",
    "            top15_pred_out = []\n",
    "\n",
    "            total_count = 0\n",
    "            gt_beam = []\n",
    "\n",
    "            # To track validation loss\n",
    "            val_loss = 0\n",
    "\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                for val_count, (pos_data, beam_val) in enumerate(val_loader):\n",
    "                    data = pos_data.to(device)\n",
    "                    labels = beam_val[:, 0].to(device)\n",
    "                    gt_beam.append(labels.detach().cpu().numpy()[0].tolist())\n",
    "                    total_count += labels.size(0)\n",
    "                    out = net(data)\n",
    "                    loss = criterion(out, labels)  # Calculate validation loss\n",
    "                    val_loss += loss.item()  # Accumulate validation loss\n",
    "                    _, top_1_pred = torch.max(out, dim=1)\n",
    "                    top1_pred_out.append(top_1_pred.detach().cpu().numpy()[0].tolist())\n",
    "                    sorted_out = torch.argsort(out, dim=1, descending=True)\n",
    "\n",
    "                    top_3_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:3])\n",
    "                    top3_pred_out.append(top_3_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                    top_5_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:5])\n",
    "                    top5_pred_out.append(top_5_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                    top_7_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:7])\n",
    "                    top7_pred_out.append(top_7_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                    top_9_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:9])\n",
    "                    top9_pred_out.append(top_9_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                    top_11_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:11])\n",
    "                    top11_pred_out.append(top_11_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                    top_13_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:13])\n",
    "                    top13_pred_out.append(top_13_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                    top_15_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:15])\n",
    "                    top15_pred_out.append(top_15_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                    reshaped_labels = labels.reshape((labels.shape[0], 1))\n",
    "                    tiled_3_labels = reshaped_labels.repeat(1, 3)\n",
    "                    tiled_5_labels = reshaped_labels.repeat(1, 5)\n",
    "                    tiled_7_labels = reshaped_labels.repeat(1, 7)\n",
    "                    tiled_9_labels = reshaped_labels.repeat(1, 9)\n",
    "                    tiled_11_labels = reshaped_labels.repeat(1, 11)\n",
    "                    tiled_13_labels = reshaped_labels.repeat(1, 13)\n",
    "                    tiled_15_labels = reshaped_labels.repeat(1, 15)\n",
    "\n",
    "                    batch_top1_acc = torch.sum(top_1_pred == labels, dtype=torch.float32)\n",
    "                    batch_top3_acc = torch.sum(top_3_pred == tiled_3_labels, dtype=torch.float32)\n",
    "                    batch_top5_acc = torch.sum(top_5_pred == tiled_5_labels, dtype=torch.float32)\n",
    "                    batch_top7_acc = torch.sum(top_7_pred == tiled_7_labels, dtype=torch.float32)\n",
    "                    batch_top9_acc = torch.sum(top_9_pred == tiled_9_labels, dtype=torch.float32)\n",
    "                    batch_top11_acc = torch.sum(top_11_pred == tiled_11_labels, dtype=torch.float32)\n",
    "                    batch_top13_acc = torch.sum(top_13_pred == tiled_13_labels, dtype=torch.float32)\n",
    "                    batch_top15_acc = torch.sum(top_15_pred == tiled_15_labels, dtype=torch.float32)\n",
    "\n",
    "                    ave_top1_acc += batch_top1_acc.item()\n",
    "                    ave_top3_acc += batch_top3_acc.item()\n",
    "                    ave_top5_acc += batch_top5_acc.item()\n",
    "                    ave_top7_acc += batch_top7_acc.item()\n",
    "                    ave_top9_acc += batch_top9_acc.item()\n",
    "                    ave_top11_acc += batch_top11_acc.item()\n",
    "                    ave_top13_acc += batch_top13_acc.item()\n",
    "                    ave_top15_acc += batch_top15_acc.item()\n",
    "\n",
    "            print(\"Total validation examples:\", total_count)\n",
    "            running_top1_acc.append(ave_top1_acc / total_count)\n",
    "            running_top3_acc.append(ave_top3_acc / total_count)\n",
    "            running_top5_acc.append(ave_top5_acc / total_count)\n",
    "            running_top7_acc.append(ave_top7_acc / total_count)\n",
    "            running_top9_acc.append(ave_top9_acc / total_count)\n",
    "            running_top11_acc.append(ave_top11_acc / total_count)\n",
    "            running_top13_acc.append(ave_top13_acc / total_count)\n",
    "            running_top15_acc.append(ave_top15_acc / total_count)\n",
    "\n",
    "            print('Validation Loss: {}'.format(val_loss / len(val_loader)))  # Print the validation loss\n",
    "            print('Average Top-1 accuracy {}'.format(running_top1_acc[-1]))\n",
    "            print('Average Top-3 accuracy {}'.format(running_top3_acc[-1]))\n",
    "            print('Average Top-5 accuracy {}'.format(running_top5_acc[-1]))\n",
    "            print('Average Top-7 accuracy {}'.format(running_top7_acc[-1]))\n",
    "            print('Average Top-9 accuracy {}'.format(running_top9_acc[-1]))\n",
    "            print('Average Top-11 accuracy {}'.format(running_top11_acc[-1]))\n",
    "            print('Average Top-13 accuracy {}'.format(running_top13_acc[-1]))\n",
    "            print('Average Top-15 accuracy {}'.format(running_top15_acc[-1]))\n",
    "\n",
    "            cur_accuracy = running_top1_acc[-1]\n",
    "\n",
    "            print(\"Current accuracy:\", cur_accuracy)\n",
    "            print(\"Best accuracy:\", best_accuracy)\n",
    "            if cur_accuracy > best_accuracy:\n",
    "                print(\"Saving the best model\")\n",
    "                net_name = checkpoint_directory + '/transformer_beam_pred-64beams'\n",
    "                torch.save(net.state_dict(), net_name)\n",
    "                best_accuracy = cur_accuracy\n",
    "            print(\"Updated best accuracy:\", best_accuracy)\n",
    "\n",
    "            print(\"Saving the predicted values in a CSV file\")\n",
    "            file_to_save = f'{save_directory}/topk_pred_beam_val_after_{epoch+1}th_epoch.csv'\n",
    "            indx = np.arange(1, len(top1_pred_out) + 1, 1)\n",
    "            df1 = pd.DataFrame()\n",
    "            df1['index'] = indx\n",
    "            df1['link_status'] = gt_beam\n",
    "            df1['top1_pred'] = top1_pred_out\n",
    "            df1['top3_pred'] = top3_pred_out\n",
    "            df1['top5_pred'] = top5_pred_out\n",
    "            df1['top7_pred'] = top7_pred_out\n",
    "            df1['top9_pred'] = top9_pred_out\n",
    "            df1['top11_pred'] = top11_pred_out\n",
    "            df1['top13_pred'] = top13_pred_out\n",
    "            df1['top15_pred'] = top15_pred_out\n",
    "            df1.to_csv(file_to_save, index=False)\n",
    "\n",
    "            LR_sch.step()\n",
    "\n",
    "        top_1[0, idx] = running_top1_acc[-1]\n",
    "        top_3[0, idx] = running_top3_acc[-1]\n",
    "        top_5[0, idx] = running_top5_acc[-1]\n",
    "        top_7[0, idx] = running_top7_acc[-1]\n",
    "        top_9[0, idx] = running_top9_acc[-1]\n",
    "        top_11[0, idx] = running_top11_acc[-1]\n",
    "        top_13[0, idx] = running_top13_acc[-1]\n",
    "        top_15[0, idx] = running_top15_acc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01975ce-ccb6-4c0a-8ab8-f58bcf4aad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ba6f8e4-3475-4e98-b993-82ad058d6403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model checkpoint\n",
    "test_dir = './scenario31_64_pos_beam_test.csv'\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv(test_dir)\n",
    "\n",
    "# Extract the 'unit1_pwr1_best-beam' data and convert it to a list\n",
    "link_status_data = test_data['original_unit1_pwr_best-beam'].tolist()\n",
    "org = test_data['original_index'].tolist()\n",
    "pwr_60ghz = test_data['original_unit1_pwr'].tolist()\n",
    "\n",
    "# Load the model checkpoint and prepare for evaluation\n",
    "checkpoint_path = f'{checkpoint_directory}/transformer_beam_pred-64beams'\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "model.eval()\n",
    "net = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca635b7d-21f4-4aa4-9a9c-f8ae6fd66e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(DataFeed(test_dir),\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85d78adc-6459-4b5d-8325-dad1759d2207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Testing\n",
      "Total examples are 702\n",
      "Testing_size 702--No. of skipped batches 0\n",
      "Average Top-1 accuracy 0.07977207977207977\n",
      "Average Top-3 accuracy 0.1794871794871795\n",
      "Average Top-5 accuracy 0.27635327635327633\n",
      "Average Top-7 accuracy 0.37037037037037035\n",
      "Average Top-9 accuracy 0.443019943019943\n",
      "Average Top-11 accuracy 0.49145299145299143\n",
      "Average Top-13 accuracy 0.5754985754985755\n",
      "Average Top-15 accuracy 0.6182336182336182\n",
      "Saving the predicted value in a csv file\n"
     ]
    }
   ],
   "source": [
    "print('Start Testing')\n",
    "ave_top1_acc = 0\n",
    "ave_top3_acc = 0\n",
    "ave_top5_acc = 0\n",
    "ave_top7_acc = 0\n",
    "ave_top9_acc = 0\n",
    "ave_top11_acc = 0\n",
    "ave_top13_acc = 0\n",
    "ave_top15_acc = 0\n",
    "\n",
    "ind_ten = torch.as_tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], device='cuda:0')\n",
    "\n",
    "top1_pred_out = []\n",
    "top3_pred_out = []\n",
    "top5_pred_out = []\n",
    "top7_pred_out = []\n",
    "top9_pred_out = []\n",
    "top11_pred_out = []\n",
    "top13_pred_out = []\n",
    "top15_pred_out = []\n",
    "\n",
    "running_top1_acc = []\n",
    "running_top3_acc = []\n",
    "running_top5_acc = []\n",
    "running_top7_acc = []\n",
    "running_top9_acc = []\n",
    "running_top11_acc = []\n",
    "running_top13_acc = []\n",
    "running_top15_acc = []\n",
    "total_count = 0\n",
    "\n",
    "gt_beam = []\n",
    "\n",
    "for val_count, (pos_data, beam_val) in enumerate(test_loader):\n",
    "    net.eval()\n",
    "    data = pos_data.to(device)\n",
    "    labels = beam_val[:,0].to(device)\n",
    "    opt.zero_grad()\n",
    "    gt_beam.extend(labels.detach().cpu().numpy().tolist())  # Append all labels from the batch\n",
    "    total_count += labels.size(0)\n",
    "    out = net(data)\n",
    "    _, top_1_pred = torch.max(out, dim=1)\n",
    "    top1_pred_out.extend(top_1_pred.detach().cpu().numpy().tolist())\n",
    "    sorted_out = torch.argsort(out, dim=1, descending=True)\n",
    "\n",
    "    top_3_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:3])\n",
    "    top3_pred_out.extend(top_3_pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "    top_5_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:5])\n",
    "    top5_pred_out.extend(top_5_pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "    top_7_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:7])\n",
    "    top7_pred_out.extend(top_7_pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "    top_9_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:9])\n",
    "    top9_pred_out.extend(top_9_pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "    top_11_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:11])\n",
    "    top11_pred_out.extend(top_11_pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "    top_13_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:13])\n",
    "    top13_pred_out.extend(top_13_pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "    top_15_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:15])\n",
    "    top15_pred_out.extend(top_15_pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "    reshaped_labels = labels.reshape((labels.shape[0], 1))\n",
    "    tiled_3_labels = reshaped_labels.repeat(1, 3)\n",
    "    tiled_5_labels = reshaped_labels.repeat(1, 5)\n",
    "    tiled_7_labels = reshaped_labels.repeat(1, 7)\n",
    "    tiled_9_labels = reshaped_labels.repeat(1, 9)\n",
    "    tiled_11_labels = reshaped_labels.repeat(1, 11)\n",
    "    tiled_13_labels = reshaped_labels.repeat(1, 13)\n",
    "    tiled_15_labels = reshaped_labels.repeat(1, 15)\n",
    "\n",
    "    batch_top1_acc = torch.sum(top_1_pred == labels, dtype=torch.float32)\n",
    "    batch_top3_acc = torch.sum(top_3_pred == tiled_3_labels, dtype=torch.float32)\n",
    "    batch_top5_acc = torch.sum(top_5_pred == tiled_5_labels, dtype=torch.float32)\n",
    "    batch_top7_acc = torch.sum(top_7_pred == tiled_7_labels, dtype=torch.float32)\n",
    "    batch_top9_acc = torch.sum(top_9_pred == tiled_9_labels, dtype=torch.float32)\n",
    "    batch_top11_acc = torch.sum(top_11_pred == tiled_11_labels, dtype=torch.float32)\n",
    "    batch_top13_acc = torch.sum(top_13_pred == tiled_13_labels, dtype=torch.float32)\n",
    "    batch_top15_acc = torch.sum(top_15_pred == tiled_15_labels, dtype=torch.float32)\n",
    "\n",
    "    ave_top1_acc += batch_top1_acc.item()\n",
    "    ave_top3_acc += batch_top3_acc.item()\n",
    "    ave_top5_acc += batch_top5_acc.item()\n",
    "    ave_top7_acc += batch_top7_acc.item()\n",
    "    ave_top9_acc += batch_top9_acc.item()\n",
    "    ave_top11_acc += batch_top11_acc.item()\n",
    "    ave_top13_acc += batch_top13_acc.item()\n",
    "    ave_top15_acc += batch_top15_acc.item()\n",
    "\n",
    "print(\"Total examples are\", total_count)\n",
    "running_top1_acc.append(ave_top1_acc / total_count)\n",
    "running_top3_acc.append(ave_top3_acc / total_count)\n",
    "running_top5_acc.append(ave_top5_acc / total_count)\n",
    "running_top7_acc.append(ave_top7_acc / total_count)\n",
    "running_top9_acc.append(ave_top9_acc / total_count)\n",
    "running_top11_acc.append(ave_top11_acc / total_count)\n",
    "running_top13_acc.append(ave_top13_acc / total_count)\n",
    "running_top15_acc.append(ave_top15_acc / total_count)\n",
    "\n",
    "print('Testing_size {}--No. of skipped batches {}'.format(total_count, skipped_batches))\n",
    "print('Average Top-1 accuracy {}'.format(running_top1_acc[-1]))\n",
    "print('Average Top-3 accuracy {}'.format(running_top3_acc[-1]))\n",
    "print('Average Top-5 accuracy {}'.format(running_top5_acc[-1]))\n",
    "print('Average Top-7 accuracy {}'.format(running_top7_acc[-1]))\n",
    "print('Average Top-9 accuracy {}'.format(running_top9_acc[-1]))\n",
    "print('Average Top-11 accuracy {}'.format(running_top11_acc[-1]))\n",
    "print('Average Top-13 accuracy {}'.format(running_top13_acc[-1]))\n",
    "print('Average Top-15 accuracy {}'.format(running_top15_acc[-1]))\n",
    "\n",
    "# Save the predicted values in a CSV file\n",
    "file_to_save = f'{save_directory}/best_epoch_eval_Test.csv'\n",
    "\n",
    "indx = np.arange(1, len(gt_beam) + 1, 1)\n",
    "# Load the model checkpoint\n",
    "test_dir = './scenario31_64_pos_beam_test.csv'\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv(test_dir)\n",
    "\n",
    "# Extract the 'unit1_pwr1_best-beam' data and convert it to a list\n",
    "link_status_data = test_data['original_unit1_pwr_best-beam'].tolist()\n",
    "org = test_data['original_index'].tolist()\n",
    "pwr_60ghz = test_data['original_unit1_pwr'].tolist()\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "df2['index'] = indx\n",
    "df2['link_status'] = gt_beam  # Add the link_status column\n",
    "df2['original_unit1_pwr3'] = pwr_60ghz\n",
    "df2['top1_pred'] = top1_pred_out\n",
    "df2['top3_pred'] = top3_pred_out\n",
    "df2['top5_pred'] = top5_pred_out\n",
    "df2['top7_pred'] = top7_pred_out\n",
    "df2['top9_pred'] = top9_pred_out\n",
    "df2['top11_pred'] = top11_pred_out\n",
    "df2['top13_pred'] = top13_pred_out\n",
    "df2['top15_pred'] = top15_pred_out\n",
    "df2.to_csv(file_to_save, index=False)\n",
    "\n",
    "print(\"Saving the predicted value in a csv file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
