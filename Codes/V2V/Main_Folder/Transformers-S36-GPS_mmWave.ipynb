{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8dcf62-03c1-42ab-9ed6-a4fa1ab8d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfomers - Scenario 36 - 64 Beams - GPS - Transfomers!\n",
    "\n",
    "# Average Top-1 accuracy 0.18911290322580646\n",
    "# Average Top-3 accuracy 0.29758064516129035\n",
    "# Average Top-5 accuracy 0.35604838709677417\n",
    "# Average Top-7 accuracy 0.4161290322580645\n",
    "# Average Top-9 accuracy 0.4560483870967742\n",
    "# Average Top-11 accuracy 0.5016129032258064\n",
    "# Average Top-13 accuracy 0.5334677419354839\n",
    "# Average Top-15 accuracy 0.569758064516129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160fc01b-1bed-4872-93c1-d780473d516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import datetime\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch as t\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.cuda as cuda\n",
    "import torch.optim as optimizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transf\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94177f6c-d38e-4828-ae84-8042153270f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Create save directory\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd31995-0b39-47eb-b51d-2535de29cb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-16-2025\n",
      "13_18\n"
     ]
    }
   ],
   "source": [
    "# year month day\n",
    "dayTime = datetime.datetime.now().strftime('%m-%d-%Y')\n",
    "# Minutes and seconds\n",
    "hourTime = datetime.datetime.now().strftime('%H_%M')\n",
    "print(dayTime + '\\n' + hourTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24eb053-3fe1-454f-9cfa-4644d6f35dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baqer\\Desktop\\V2X_CNN_All\\Scenario36_64-Beams\\Main_Folder//saved_folder//01-16-2025_13_18\n"
     ]
    }
   ],
   "source": [
    "pwd = os.getcwd() + '//' + 'saved_folder' + '//' + dayTime + '_' + hourTime\n",
    "print(pwd)\n",
    "# Determine whether the folder already exists\n",
    "isExists = os.path.exists(pwd)\n",
    "if not isExists:\n",
    "    os.makedirs(pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c7f6d59-1c34-4482-8072-2916ba6eaba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Baqer\\\\Desktop\\\\V2X_CNN_All\\\\Scenario36_64-Beams\\\\Main_Folder//saved_folder//01-16-2025_13_18\\\\scenario36_64_pos_beam_test.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the training files to the saved directory\n",
    "shutil.copy('./scenario36_64_pos_beam_train.csv', pwd)\n",
    "shutil.copy('./scenario36_64_pos_beam_val.csv', pwd)\n",
    "shutil.copy('./scenario36_64_pos_beam_test.csv', pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3579b0e-dc12-477d-88ff-62fb96803150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder to save analysis files and checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eff5935-f683-4a0f-bc42-126c2cde53bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = pwd + '//' + 'saved_analysis_files'\n",
    "checkpoint_directory = pwd + '//' + 'checkpoint'\n",
    "\n",
    "isExists = os.path.exists(save_directory)\n",
    "if not isExists:\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "isExists = os.path.exists(checkpoint_directory)\n",
    "if not isExists:\n",
    "    os.makedirs(checkpoint_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0bb698-f628-4836-a68c-556484486afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Data Feeding: Create data sample list\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0382b04-811c-4912-a418-9df85dab10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFeed(Dataset):\n",
    "    def __init__(self, root_dir, nat_sort=False, transform=None, init_shuffle=True):\n",
    "        self.root = root_dir\n",
    "        self.samples = self.create_samples(self.root, shuffle=init_shuffle, nat_sort=nat_sort)\n",
    "        self.transform = transform\n",
    "\n",
    "    def create_samples(self, root, shuffle=False, nat_sort=False):\n",
    "        f = pd.read_csv(root)\n",
    "        data_samples = []\n",
    "        for idx, row in f.iterrows():\n",
    "            data = list(row.values[1:])\n",
    "            data_samples.append(data)\n",
    "        return data_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        pos_val = sample[:1]\n",
    "        pos_val = ast.literal_eval(pos_val[0])\n",
    "        pos_val = np.asarray(pos_val)\n",
    "        pos_centers = sample[1:2]\n",
    "        pos_centers = np.asarray(pos_centers)\n",
    "        return torch.tensor(pos_val, dtype=torch.float32), torch.tensor(pos_centers, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddacecf7-6da8-4d4d-8f65-a759c3d9f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Training, Testing, and Validation!\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53b7b3-30e5-4819-83c2-a4b80b096c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ab916a-a336-4d11-92fd-505d18e7f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optimizer\n",
    "import ast\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_features, num_output, d_model=512, nhead=8, num_encoder_layers=6):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(num_features, d_model)\n",
    "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers)\n",
    "        self.fc = nn.Linear(d_model, num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).unsqueeze(0)  # Add batch dimension\n",
    "        transformer_output = self.transformer(x, x)\n",
    "        output = self.fc(transformer_output.squeeze(0))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2c02a-8046-4b3d-89e8-de751f48b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10dcbbba-d52f-47df-9a15-c57f833d1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Hyper-parameters\n",
    "batch_size = 128\n",
    "val_batch_size = 1\n",
    "lr = 0.01\n",
    "decay = 1e-4\n",
    "num_epochs = 20 # After 1st epoch, the accuracy remains same!\n",
    "train_size = [1]\n",
    "\n",
    "# Hyperparameters for our network\n",
    "input_size = 2\n",
    "node = 512\n",
    "output_size = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a1923e-e00d-4d1f-bb3a-fb8505c96773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size is 1\n",
      "Epoch No. 1\n",
      "Training-Batch No.100\n",
      "Loss = 3.724503517150879\n",
      "Epoch 1 Training Loss: 3.9919\n",
      "Start Training and Validation\n",
      "Epoch 1 Validation Loss: 7.3721\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.0009908707999877467\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.3489247311827957\n",
      "Average Top-7 accuracy 0.4083333333333333\n",
      "Average Top-9 accuracy 0.45\n",
      "Average Top-11 accuracy 0.5056451612903226\n",
      "Average Top-13 accuracy 0.537768817204301\n",
      "Average Top-15 accuracy 0.5758064516129032\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0\n",
      "Saving the best model\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 2\n",
      "Training-Batch No.200\n",
      "Loss = 3.683753490447998\n",
      "Epoch 2 Training Loss: 3.6750\n",
      "Start Training and Validation\n",
      "Epoch 2 Validation Loss: 7.3146\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.00098314967714978\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.35591397849462364\n",
      "Average Top-7 accuracy 0.4083333333333333\n",
      "Average Top-9 accuracy 0.4635752688172043\n",
      "Average Top-11 accuracy 0.5056451612903226\n",
      "Average Top-13 accuracy 0.5408602150537635\n",
      "Average Top-15 accuracy 0.568010752688172\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 3\n",
      "Training-Batch No.300\n",
      "Loss = 3.7219810485839844\n",
      "Epoch 3 Training Loss: 3.6650\n",
      "Start Training and Validation\n",
      "Epoch 3 Validation Loss: 7.2912\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.0009800051512098241\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.35591397849462364\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.4635752688172043\n",
      "Average Top-11 accuracy 0.5056451612903226\n",
      "Average Top-13 accuracy 0.5466397849462366\n",
      "Average Top-15 accuracy 0.5778225806451613\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 4\n",
      "Training-Batch No.400\n",
      "Loss = 3.529362678527832\n",
      "Epoch 4 Training Loss: 3.6600\n",
      "Start Training and Validation\n",
      "Epoch 4 Validation Loss: 7.3028\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.0009815586581636694\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.35591397849462364\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.4639784946236559\n",
      "Average Top-11 accuracy 0.5010752688172043\n",
      "Average Top-13 accuracy 0.5466397849462366\n",
      "Average Top-15 accuracy 0.5778225806451613\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 5\n",
      "Training-Batch No.500\n",
      "Loss = 3.7068755626678467\n",
      "Epoch 5 Training Loss: 3.6582\n",
      "Start Training and Validation\n",
      "Epoch 5 Validation Loss: 7.3037\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.0009816824297213611\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.36478494623655916\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.4614247311827957\n",
      "Average Top-11 accuracy 0.5010752688172043\n",
      "Average Top-13 accuracy 0.5466397849462366\n",
      "Average Top-15 accuracy 0.5806451612903226\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 6\n",
      "Training-Batch No.600\n",
      "Loss = 3.6203441619873047\n",
      "Training-Batch No.700\n",
      "Loss = 3.6494579315185547\n",
      "Epoch 6 Training Loss: 3.6535\n",
      "Start Training and Validation\n",
      "Epoch 6 Validation Loss: 7.2926\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.0009801882660389635\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.36478494623655916\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.46841397849462363\n",
      "Average Top-11 accuracy 0.5056451612903226\n",
      "Average Top-13 accuracy 0.5466397849462366\n",
      "Average Top-15 accuracy 0.5809139784946237\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 7\n",
      "Training-Batch No.800\n",
      "Loss = 3.675509452819824\n",
      "Epoch 7 Training Loss: 3.6505\n",
      "Start Training and Validation\n",
      "Epoch 7 Validation Loss: 7.3012\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.0009813393120113268\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.35591397849462364\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.46102150537634407\n",
      "Average Top-11 accuracy 0.5056451612903226\n",
      "Average Top-13 accuracy 0.5439516129032258\n",
      "Average Top-15 accuracy 0.5806451612903226\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 8\n",
      "Training-Batch No.900\n",
      "Loss = 3.6208622455596924\n",
      "Epoch 8 Training Loss: 3.6494\n",
      "Start Training and Validation\n",
      "Epoch 8 Validation Loss: 7.2931\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.000980258563175713\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.35591397849462364\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.46841397849462363\n",
      "Average Top-11 accuracy 0.505510752688172\n",
      "Average Top-13 accuracy 0.5439516129032258\n",
      "Average Top-15 accuracy 0.5806451612903226\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 9\n",
      "Training-Batch No.1000\n",
      "Loss = 3.7104620933532715\n",
      "Epoch 9 Training Loss: 3.6489\n",
      "Start Training and Validation\n",
      "Epoch 9 Validation Loss: 7.2919\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.0009800989942142543\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.36478494623655916\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.46102150537634407\n",
      "Average Top-11 accuracy 0.505510752688172\n",
      "Average Top-13 accuracy 0.5439516129032258\n",
      "Average Top-15 accuracy 0.5809139784946237\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 10\n",
      "Training-Batch No.1100\n",
      "Loss = 3.735952377319336\n",
      "Epoch 10 Training Loss: 3.6470\n",
      "Start Training and Validation\n",
      "Epoch 10 Validation Loss: 7.2900\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.0009798335190614753\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.36478494623655916\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.46841397849462363\n",
      "Average Top-11 accuracy 0.5080645161290323\n",
      "Average Top-13 accuracy 0.5439516129032258\n",
      "Average Top-15 accuracy 0.5809139784946237\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 11\n",
      "Training-Batch No.1200\n",
      "Loss = 3.6635022163391113\n",
      "Epoch 11 Training Loss: 3.6456\n",
      "Start Training and Validation\n",
      "Epoch 11 Validation Loss: 7.2837\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.00097899256144673\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.35591397849462364\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.46841397849462363\n",
      "Average Top-11 accuracy 0.5080645161290323\n",
      "Average Top-13 accuracy 0.5439516129032258\n",
      "Average Top-15 accuracy 0.581989247311828\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 12\n",
      "Training-Batch No.1300\n",
      "Loss = 3.6010525226593018\n",
      "Training-Batch No.1400\n",
      "Loss = 3.5713396072387695\n",
      "Epoch 12 Training Loss: 3.6445\n",
      "Start Training and Validation\n",
      "Epoch 12 Validation Loss: 7.2794\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.0009784175849032203\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.36478494623655916\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.4635752688172043\n",
      "Average Top-11 accuracy 0.5006720430107527\n",
      "Average Top-13 accuracy 0.5439516129032258\n",
      "Average Top-15 accuracy 0.5809139784946237\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 13\n",
      "Training-Batch No.1500\n",
      "Loss = 3.708606004714966\n",
      "Epoch 13 Training Loss: 3.6439\n",
      "Start Training and Validation\n",
      "Epoch 13 Validation Loss: 7.2849\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.000979148611397926\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.35591397849462364\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.46102150537634407\n",
      "Average Top-11 accuracy 0.5006720430107527\n",
      "Average Top-13 accuracy 0.5408602150537635\n",
      "Average Top-15 accuracy 0.5806451612903226\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 14\n",
      "Training-Batch No.1600\n",
      "Loss = 3.7521350383758545\n",
      "Epoch 14 Training Loss: 3.6437\n",
      "Start Training and Validation\n",
      "Epoch 14 Validation Loss: 7.2840\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.000979027761632493\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.36478494623655916\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.4614247311827957\n",
      "Average Top-11 accuracy 0.505510752688172\n",
      "Average Top-13 accuracy 0.5466397849462366\n",
      "Average Top-15 accuracy 0.5788978494623656\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 15\n",
      "Training-Batch No.1700\n",
      "Loss = 3.602045774459839\n",
      "Epoch 15 Training Loss: 3.6440\n",
      "Start Training and Validation\n",
      "Epoch 15 Validation Loss: 7.2763\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.0009780039016365426\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.36478494623655916\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.4635752688172043\n",
      "Average Top-11 accuracy 0.5080645161290323\n",
      "Average Top-13 accuracy 0.5466397849462366\n",
      "Average Top-15 accuracy 0.5809139784946237\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 16\n",
      "Training-Batch No.1800\n",
      "Loss = 3.6539504528045654\n",
      "Epoch 16 Training Loss: 3.6383\n",
      "Start Training and Validation\n",
      "Epoch 16 Validation Loss: 7.2576\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.000975489026403507\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.36478494623655916\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.4635752688172043\n",
      "Average Top-11 accuracy 0.5068548387096774\n",
      "Average Top-13 accuracy 0.5478494623655914\n",
      "Average Top-15 accuracy 0.5865591397849462\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 17\n",
      "Training-Batch No.1900\n",
      "Loss = 3.580535650253296\n",
      "Epoch 17 Training Loss: 3.6355\n",
      "Start Training and Validation\n",
      "Epoch 17 Validation Loss: 7.2573\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.0009754484721068247\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.36478494623655916\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.4622311827956989\n",
      "Average Top-11 accuracy 0.5068548387096774\n",
      "Average Top-13 accuracy 0.5478494623655914\n",
      "Average Top-15 accuracy 0.5865591397849462\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 18\n",
      "Training-Batch No.2000\n",
      "Loss = 3.5738160610198975\n",
      "Training-Batch No.2100\n",
      "Loss = 3.671387195587158\n",
      "Epoch 18 Training Loss: 3.6358\n",
      "Start Training and Validation\n",
      "Epoch 18 Validation Loss: 7.2572\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.0009754338421867354\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.36478494623655916\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.4622311827956989\n",
      "Average Top-11 accuracy 0.5068548387096774\n",
      "Average Top-13 accuracy 0.5478494623655914\n",
      "Average Top-15 accuracy 0.5865591397849462\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 19\n",
      "Training-Batch No.2200\n",
      "Loss = 3.693732738494873\n",
      "Epoch 19 Training Loss: 3.6356\n",
      "Start Training and Validation\n",
      "Epoch 19 Validation Loss: 7.2573\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.0009754370307018543\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.36478494623655916\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.4622311827956989\n",
      "Average Top-11 accuracy 0.5068548387096774\n",
      "Average Top-13 accuracy 0.5478494623655914\n",
      "Average Top-15 accuracy 0.5865591397849462\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n",
      "Epoch No. 20\n",
      "Training-Batch No.2300\n",
      "Loss = 3.523009777069092\n",
      "Epoch 20 Training Loss: 3.6354\n",
      "Start Training and Validation\n",
      "Epoch 20 Validation Loss: 7.2572\n",
      "Total training examples: 7440\n",
      "Validation Loss: 0.0009754359248733987\n",
      "Average Top-1 accuracy 0.18508064516129033\n",
      "Average Top-3 accuracy 0.29274193548387095\n",
      "Average Top-5 accuracy 0.36478494623655916\n",
      "Average Top-7 accuracy 0.41935483870967744\n",
      "Average Top-9 accuracy 0.4622311827956989\n",
      "Average Top-11 accuracy 0.5068548387096774\n",
      "Average Top-13 accuracy 0.5478494623655914\n",
      "Average Top-15 accuracy 0.5865591397849462\n",
      "Current accuracy: 0.18508064516129033\n",
      "Best accuracy: 0.18508064516129033\n",
      "Updated best accuracy: 0.18508064516129033\n",
      "Saving the predicted values in a CSV file\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'scenario36_64_pos_beam_train.csv'\n",
    "val_dir = 'scenario36_64_pos_beam_val.csv'\n",
    "\n",
    "train_loader = DataLoader(DataFeed(train_dir),\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False)\n",
    "val_loader = DataLoader(DataFeed(val_dir),\n",
    "                        batch_size=val_batch_size,\n",
    "                        shuffle=False)\n",
    "\n",
    "class TransformerBeamPred(nn.Module):\n",
    "    def __init__(self, num_features, num_output):\n",
    "        super(TransformerBeamPred, self).__init__()\n",
    "        self.transformer = TransformerModel(num_features, num_output)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.transformer(inputs)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TransformerBeamPred(input_size, num_output=output_size).to(device)\n",
    "val_acc = []\n",
    "\n",
    "top_1 = np.zeros((1, len(train_size)))\n",
    "top_3 = np.zeros((1, len(train_size)))\n",
    "top_5 = np.zeros((1, len(train_size)))\n",
    "top_7 = np.zeros((1, len(train_size)))\n",
    "top_9 = np.zeros((1, len(train_size)))\n",
    "top_11 = np.zeros((1, len(train_size)))\n",
    "top_13 = np.zeros((1, len(train_size)))\n",
    "top_15 = np.zeros((1, len(train_size)))\n",
    "acc_loss = 0\n",
    "itr = []\n",
    "\n",
    "for idx, n in enumerate(train_size):\n",
    "    print('Training size is {}'.format(n))\n",
    "    net = model\n",
    "    layers = list(net.children())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    opt = optimizer.Adam(net.parameters(), lr=lr, weight_decay=decay)\n",
    "    LR_sch = optimizer.lr_scheduler.MultiStepLR(opt, [15, 25, 40], gamma=0.1, last_epoch=-1)\n",
    "\n",
    "    count = 0\n",
    "    running_loss = []\n",
    "    running_top1_acc = []\n",
    "    running_top3_acc = []\n",
    "    running_top5_acc = []\n",
    "    running_top7_acc = []\n",
    "    running_top9_acc = []\n",
    "    running_top11_acc = []\n",
    "    running_top13_acc = []\n",
    "    running_top15_acc = []\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch No. ' + str(epoch + 1))\n",
    "        skipped_batches = 0\n",
    "        epoch_train_loss = 0  # To track the training loss for the epoch # Added\n",
    "        net.train()\n",
    "        for tr_count, (pos_data, beam_val) in enumerate(train_loader):\n",
    "            data = pos_data.to(device)\n",
    "            label = beam_val[:, 0].to(device)\n",
    "            opt.zero_grad()\n",
    "            out = net(data)\n",
    "            loss = criterion(out, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            batch_loss = loss.item()\n",
    "            acc_loss += batch_loss\n",
    "            epoch_train_loss += batch_loss  # Accumulate batch loss for the epoch # Added\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                print('Training-Batch No.' + str(count))\n",
    "                running_loss.append(batch_loss)\n",
    "                itr.append(count)\n",
    "                print('Loss = ' + str(running_loss[-1]))\n",
    "\n",
    "        epoch_train_loss /= len(train_loader)  # Calculate average training loss for the epoch # Added\n",
    "        print(f'Epoch {epoch + 1} Training Loss: {epoch_train_loss:.4f}') # Added\n",
    "        \n",
    "        print('Start Training and Validation')\n",
    "        \n",
    "        ave_top1_acc = 0\n",
    "        ave_top3_acc = 0\n",
    "        ave_top5_acc = 0\n",
    "        ave_top7_acc = 0\n",
    "        ave_top9_acc = 0\n",
    "        ave_top11_acc = 0\n",
    "        ave_top13_acc = 0\n",
    "        ave_top15_acc = 0\n",
    "        val_loss = 0  # To track the validation loss # Added\n",
    "        ind_ten = torch.as_tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], device=device)\n",
    "        \n",
    "        top1_pred_out = []\n",
    "        top3_pred_out = []\n",
    "        top5_pred_out = []\n",
    "        top7_pred_out = []\n",
    "        top9_pred_out = []\n",
    "        top11_pred_out = []\n",
    "        top13_pred_out = []\n",
    "        top15_pred_out = []\n",
    "\n",
    "        total_count = 0\n",
    "        gt_beam = []\n",
    "\n",
    "        # To track validation loss\n",
    "        val_loss = 0\n",
    "\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_count, (pos_data, beam_val) in enumerate(val_loader):\n",
    "                data = pos_data.to(device)\n",
    "                labels = beam_val[:, 0].to(device)\n",
    "                gt_beam.append(labels.detach().cpu().numpy()[0].tolist())\n",
    "                total_count += labels.size(0)\n",
    "                out = net(data)\n",
    "                loss = criterion(out, labels)  # Calculate validation loss\n",
    "                val_loss += loss.item()  # Accumulate validation loss\n",
    "                _, top_1_pred = torch.max(out, dim=1)\n",
    "                    \n",
    "                val_batch_loss = criterion(out, labels).item()  # Calculate validation loss for the batch # Added\n",
    "                val_loss += val_batch_loss  # Accumulate batch loss for the epoch # Added\n",
    "                \n",
    "                top1_pred_out.append(top_1_pred.detach().cpu().numpy()[0].tolist())\n",
    "                sorted_out = torch.argsort(out, dim=1, descending=True)\n",
    "\n",
    "                top_3_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:3])\n",
    "                top3_pred_out.append(top_3_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                top_5_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:5])\n",
    "                top5_pred_out.append(top_5_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                top_7_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:7])\n",
    "                top7_pred_out.append(top_7_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                top_9_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:9])\n",
    "                top9_pred_out.append(top_9_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                top_11_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:11])\n",
    "                top11_pred_out.append(top_11_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                top_13_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:13])\n",
    "                top13_pred_out.append(top_13_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                top_15_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:15])\n",
    "                top15_pred_out.append(top_15_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                reshaped_labels = labels.reshape((labels.shape[0], 1))\n",
    "                tiled_3_labels = reshaped_labels.repeat(1, 3)\n",
    "                tiled_5_labels = reshaped_labels.repeat(1, 5)\n",
    "                tiled_7_labels = reshaped_labels.repeat(1, 7)\n",
    "                tiled_9_labels = reshaped_labels.repeat(1, 9)\n",
    "                tiled_11_labels = reshaped_labels.repeat(1, 11)\n",
    "                tiled_13_labels = reshaped_labels.repeat(1, 13)\n",
    "                tiled_15_labels = reshaped_labels.repeat(1, 15)\n",
    "\n",
    "                batch_top1_acc = torch.sum(top_1_pred == labels, dtype=torch.float32)\n",
    "                batch_top3_acc = torch.sum(top_3_pred == tiled_3_labels, dtype=torch.float32)\n",
    "                batch_top5_acc = torch.sum(top_5_pred == tiled_5_labels, dtype=torch.float32)\n",
    "                batch_top7_acc = torch.sum(top_7_pred == tiled_7_labels, dtype=torch.float32)\n",
    "                batch_top9_acc = torch.sum(top_9_pred == tiled_9_labels, dtype=torch.float32)\n",
    "                batch_top11_acc = torch.sum(top_11_pred == tiled_11_labels, dtype=torch.float32)\n",
    "                batch_top13_acc = torch.sum(top_13_pred == tiled_13_labels, dtype=torch.float32)\n",
    "                batch_top15_acc = torch.sum(top_15_pred == tiled_15_labels, dtype=torch.float32)\n",
    "\n",
    "                ave_top1_acc += batch_top1_acc.item()\n",
    "                ave_top3_acc += batch_top3_acc.item()\n",
    "                ave_top5_acc += batch_top5_acc.item()\n",
    "                ave_top7_acc += batch_top7_acc.item()\n",
    "                ave_top9_acc += batch_top9_acc.item()\n",
    "                ave_top11_acc += batch_top11_acc.item()\n",
    "                ave_top13_acc += batch_top13_acc.item()\n",
    "                ave_top15_acc += batch_top15_acc.item()\n",
    "                \n",
    "        val_loss /= len(val_loader)  # Calculate average validation loss for the epoch # Added\n",
    "        print(f'Epoch {epoch + 1} Validation Loss: {val_loss:.4f}') # Added\n",
    "        \n",
    "        print(\"Total training examples:\", total_count)\n",
    "        running_top1_acc.append(ave_top1_acc / total_count)\n",
    "        running_top3_acc.append(ave_top3_acc / total_count)\n",
    "        running_top5_acc.append(ave_top5_acc / total_count)\n",
    "        running_top7_acc.append(ave_top7_acc / total_count)\n",
    "        running_top9_acc.append(ave_top9_acc / total_count)\n",
    "        running_top11_acc.append(ave_top11_acc / total_count)\n",
    "        running_top13_acc.append(ave_top13_acc / total_count)\n",
    "        running_top15_acc.append(ave_top15_acc / total_count)\n",
    "\n",
    "        print('Validation Loss: {}'.format(val_loss / len(val_loader)))  # Print the validation loss\n",
    "        print('Average Top-1 accuracy {}'.format(running_top1_acc[-1]))\n",
    "        print('Average Top-3 accuracy {}'.format(running_top3_acc[-1]))\n",
    "        print('Average Top-5 accuracy {}'.format(running_top5_acc[-1]))\n",
    "        print('Average Top-7 accuracy {}'.format(running_top7_acc[-1]))\n",
    "        print('Average Top-9 accuracy {}'.format(running_top9_acc[-1]))\n",
    "        print('Average Top-11 accuracy {}'.format(running_top11_acc[-1]))\n",
    "        print('Average Top-13 accuracy {}'.format(running_top13_acc[-1]))\n",
    "        print('Average Top-15 accuracy {}'.format(running_top15_acc[-1]))\n",
    "\n",
    "        cur_accuracy = running_top1_acc[-1]\n",
    "\n",
    "        print(\"Current accuracy:\", cur_accuracy)\n",
    "        print(\"Best accuracy:\", best_accuracy)\n",
    "        if cur_accuracy > best_accuracy:\n",
    "            print(\"Saving the best model\")\n",
    "            net_name = checkpoint_directory + '/transformer_beam_pred-64beams'\n",
    "            torch.save(net.state_dict(), net_name)\n",
    "            best_accuracy = cur_accuracy\n",
    "        print(\"Updated best accuracy:\", best_accuracy)\n",
    "\n",
    "        print(\"Saving the predicted values in a CSV file\")\n",
    "        file_to_save = f'{save_directory}/topk_pred_beam_val_after_{epoch+1}th_epoch.csv'\n",
    "        indx = np.arange(1, len(top1_pred_out) + 1, 1)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['index'] = indx\n",
    "        df1['link_status'] = gt_beam\n",
    "        df1['top1_pred'] = top1_pred_out\n",
    "        df1['top3_pred'] = top3_pred_out\n",
    "        df1['top5_pred'] = top5_pred_out\n",
    "        df1['top7_pred'] = top7_pred_out\n",
    "        df1['top9_pred'] = top9_pred_out\n",
    "        df1['top11_pred'] = top11_pred_out\n",
    "        df1['top13_pred'] = top13_pred_out\n",
    "        df1['top15_pred'] = top15_pred_out\n",
    "        df1.to_csv(file_to_save, index=False)\n",
    "\n",
    "        LR_sch.step()\n",
    "\n",
    "    top_1[0, idx] = running_top1_acc[-1]\n",
    "    top_3[0, idx] = running_top3_acc[-1]\n",
    "    top_5[0, idx] = running_top5_acc[-1]\n",
    "    top_7[0, idx] = running_top7_acc[-1]\n",
    "    top_9[0, idx] = running_top9_acc[-1]\n",
    "    top_11[0, idx] = running_top11_acc[-1]\n",
    "    top_13[0, idx] = running_top13_acc[-1]\n",
    "    top_15[0, idx] = running_top15_acc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01975ce-ccb6-4c0a-8ab8-f58bcf4aad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ba6f8e4-3475-4e98-b993-82ad058d6403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model checkpoint\n",
    "test_dir = './scenario36_64_pos_beam_test.csv'\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv(test_dir)\n",
    "\n",
    "# Extract the 'unit1_pwr1_best-beam' data and convert it to a list\n",
    "link_status_data = test_data['original_unit1_pwr3_best-beam'].tolist()\n",
    "org = test_data['original_index'].tolist()\n",
    "pwr_60ghz = test_data['original_unit1_pwr3'].tolist()\n",
    "\n",
    "# Load the model checkpoint and prepare for evaluation\n",
    "checkpoint_path = f'{checkpoint_directory}/transformer_beam_pred-64beams'\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "model.eval()\n",
    "net = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca635b7d-21f4-4aa4-9a9c-f8ae6fd66e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(DataFeed(test_dir),\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85d78adc-6459-4b5d-8325-dad1759d2207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Testing\n",
      "Total examples are 2480\n",
      "Testing_size 2480--No. of skipped batches 0\n",
      "Average Top-1 accuracy 0.18911290322580646\n",
      "Average Top-3 accuracy 0.29758064516129035\n",
      "Average Top-5 accuracy 0.35604838709677417\n",
      "Average Top-7 accuracy 0.4161290322580645\n",
      "Average Top-9 accuracy 0.4560483870967742\n",
      "Average Top-11 accuracy 0.5016129032258064\n",
      "Average Top-13 accuracy 0.5334677419354839\n",
      "Average Top-15 accuracy 0.569758064516129\n",
      "Saving the predicted value in a csv file\n"
     ]
    }
   ],
   "source": [
    "print('Start Testing')\n",
    "ave_top1_acc = 0\n",
    "ave_top3_acc = 0\n",
    "ave_top5_acc = 0\n",
    "ave_top7_acc = 0\n",
    "ave_top9_acc = 0\n",
    "ave_top11_acc = 0\n",
    "ave_top13_acc = 0\n",
    "ave_top15_acc = 0\n",
    "\n",
    "ind_ten = torch.as_tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], device='cuda:0')\n",
    "\n",
    "top1_pred_out = []\n",
    "top3_pred_out = []\n",
    "top5_pred_out = []\n",
    "top7_pred_out = []\n",
    "top9_pred_out = []\n",
    "top11_pred_out = []\n",
    "top13_pred_out = []\n",
    "top15_pred_out = []\n",
    "\n",
    "running_top1_acc = []\n",
    "running_top3_acc = []\n",
    "running_top5_acc = []\n",
    "running_top7_acc = []\n",
    "running_top9_acc = []\n",
    "running_top11_acc = []\n",
    "running_top13_acc = []\n",
    "running_top15_acc = []\n",
    "total_count = 0\n",
    "\n",
    "gt_beam = []\n",
    "\n",
    "for val_count, (pos_data, beam_val) in enumerate(test_loader):\n",
    "    net.eval()\n",
    "    data = pos_data.to(device)\n",
    "    labels = beam_val[:,0].to(device)\n",
    "    opt.zero_grad()\n",
    "    gt_beam.extend(labels.detach().cpu().numpy().tolist())  # Append all labels from the batch\n",
    "    total_count += labels.size(0)\n",
    "    out = net(data)\n",
    "    _, top_1_pred = torch.max(out, dim=1)\n",
    "    top1_pred_out.extend(top_1_pred.detach().cpu().numpy().tolist())\n",
    "    sorted_out = torch.argsort(out, dim=1, descending=True)\n",
    "\n",
    "    top_3_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:3])\n",
    "    top3_pred_out.extend(top_3_pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "    top_5_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:5])\n",
    "    top5_pred_out.extend(top_5_pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "    top_7_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:7])\n",
    "    top7_pred_out.extend(top_7_pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "    top_9_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:9])\n",
    "    top9_pred_out.extend(top_9_pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "    top_11_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:11])\n",
    "    top11_pred_out.extend(top_11_pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "    top_13_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:13])\n",
    "    top13_pred_out.extend(top_13_pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "    top_15_pred = torch.index_select(sorted_out, dim=1, index=ind_ten[0:15])\n",
    "    top15_pred_out.extend(top_15_pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "    reshaped_labels = labels.reshape((labels.shape[0], 1))\n",
    "    tiled_3_labels = reshaped_labels.repeat(1, 3)\n",
    "    tiled_5_labels = reshaped_labels.repeat(1, 5)\n",
    "    tiled_7_labels = reshaped_labels.repeat(1, 7)\n",
    "    tiled_9_labels = reshaped_labels.repeat(1, 9)\n",
    "    tiled_11_labels = reshaped_labels.repeat(1, 11)\n",
    "    tiled_13_labels = reshaped_labels.repeat(1, 13)\n",
    "    tiled_15_labels = reshaped_labels.repeat(1, 15)\n",
    "\n",
    "    batch_top1_acc = torch.sum(top_1_pred == labels, dtype=torch.float32)\n",
    "    batch_top3_acc = torch.sum(top_3_pred == tiled_3_labels, dtype=torch.float32)\n",
    "    batch_top5_acc = torch.sum(top_5_pred == tiled_5_labels, dtype=torch.float32)\n",
    "    batch_top7_acc = torch.sum(top_7_pred == tiled_7_labels, dtype=torch.float32)\n",
    "    batch_top9_acc = torch.sum(top_9_pred == tiled_9_labels, dtype=torch.float32)\n",
    "    batch_top11_acc = torch.sum(top_11_pred == tiled_11_labels, dtype=torch.float32)\n",
    "    batch_top13_acc = torch.sum(top_13_pred == tiled_13_labels, dtype=torch.float32)\n",
    "    batch_top15_acc = torch.sum(top_15_pred == tiled_15_labels, dtype=torch.float32)\n",
    "\n",
    "    ave_top1_acc += batch_top1_acc.item()\n",
    "    ave_top3_acc += batch_top3_acc.item()\n",
    "    ave_top5_acc += batch_top5_acc.item()\n",
    "    ave_top7_acc += batch_top7_acc.item()\n",
    "    ave_top9_acc += batch_top9_acc.item()\n",
    "    ave_top11_acc += batch_top11_acc.item()\n",
    "    ave_top13_acc += batch_top13_acc.item()\n",
    "    ave_top15_acc += batch_top15_acc.item()\n",
    "\n",
    "print(\"Total examples are\", total_count)\n",
    "running_top1_acc.append(ave_top1_acc / total_count)\n",
    "running_top3_acc.append(ave_top3_acc / total_count)\n",
    "running_top5_acc.append(ave_top5_acc / total_count)\n",
    "running_top7_acc.append(ave_top7_acc / total_count)\n",
    "running_top9_acc.append(ave_top9_acc / total_count)\n",
    "running_top11_acc.append(ave_top11_acc / total_count)\n",
    "running_top13_acc.append(ave_top13_acc / total_count)\n",
    "running_top15_acc.append(ave_top15_acc / total_count)\n",
    "\n",
    "print('Testing_size {}--No. of skipped batches {}'.format(total_count, skipped_batches))\n",
    "print('Average Top-1 accuracy {}'.format(running_top1_acc[-1]))\n",
    "print('Average Top-3 accuracy {}'.format(running_top3_acc[-1]))\n",
    "print('Average Top-5 accuracy {}'.format(running_top5_acc[-1]))\n",
    "print('Average Top-7 accuracy {}'.format(running_top7_acc[-1]))\n",
    "print('Average Top-9 accuracy {}'.format(running_top9_acc[-1]))\n",
    "print('Average Top-11 accuracy {}'.format(running_top11_acc[-1]))\n",
    "print('Average Top-13 accuracy {}'.format(running_top13_acc[-1]))\n",
    "print('Average Top-15 accuracy {}'.format(running_top15_acc[-1]))\n",
    "\n",
    "# Save the predicted values in a CSV file\n",
    "file_to_save = f'{save_directory}/best_epoch_eval_Test.csv'\n",
    "\n",
    "indx = np.arange(1, len(gt_beam) + 1, 1)\n",
    "# Load the model checkpoint\n",
    "test_dir = './scenario36_64_pos_beam_test.csv'\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv(test_dir)\n",
    "\n",
    "# Extract the 'unit1_pwr1_best-beam' data and convert it to a list\n",
    "link_status_data = test_data['original_unit1_pwr3_best-beam'].tolist()\n",
    "org = test_data['original_index'].tolist()\n",
    "pwr_60ghz = test_data['original_unit1_pwr3'].tolist()\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "df2['index'] = indx\n",
    "df2['link_status'] = gt_beam  # Add the link_status column\n",
    "df2['original_unit1_pwr3'] = pwr_60ghz\n",
    "df2['top1_pred'] = top1_pred_out\n",
    "df2['top3_pred'] = top3_pred_out\n",
    "df2['top5_pred'] = top5_pred_out\n",
    "df2['top7_pred'] = top7_pred_out\n",
    "df2['top9_pred'] = top9_pred_out\n",
    "df2['top11_pred'] = top11_pred_out\n",
    "df2['top13_pred'] = top13_pred_out\n",
    "df2['top15_pred'] = top15_pred_out\n",
    "df2.to_csv(file_to_save, index=False)\n",
    "\n",
    "print(\"Saving the predicted value in a csv file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
