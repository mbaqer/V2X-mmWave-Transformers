{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07f0868-196a-4215-9be3-8137263ec221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Fusion with concatination RGB, GPS, and LiDAR Transformers: DeepSense Scenario 36 64 Beams!\n",
    "# MLP\n",
    "\n",
    "# Average Top-1 accuracy 0.14637096774193548\n",
    "# Average Top-3 accuracy 0.23911290322580644\n",
    "# Average Top-5 accuracy 0.29274193548387095\n",
    "# Average Top-7 accuracy 0.34596774193548385\n",
    "# Average Top-9 accuracy 0.39838709677419354\n",
    "# Average Top-11 accuracy 0.43709677419354837\n",
    "# Average Top-13 accuracy 0.4717741935483871\n",
    "# Average Top-15 accuracy 0.4963709677419355"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bcd5875-6e40-45de-a1e8-60c49cfb7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15531c3f-d42a-4468-a2ac-82e3189f68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70c2ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as transf\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from skimage import io\n",
    "import os\n",
    "import datetime\n",
    "import torch as t\n",
    "import pandas as pd\n",
    "import torch.cuda as cuda\n",
    "from torchsummary import summary\n",
    "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plyfile import PlyData, PlyElement\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8924f11c-c048-4e07-8676-83fbe880e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Hyper-parameters\n",
    "batch_size = 4 # 16, 32 out of memory problem!\n",
    "val_batch_size = 1\n",
    "lr = 0.001\n",
    "decay = 1e-4\n",
    "num_epochs = 1\n",
    "train_size = [1]\n",
    "\n",
    "# Hyperparameters for our network\n",
    "input_size = 2\n",
    "node = 512\n",
    "output_size = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47f14f46-4153-40d2-957a-a1ea8c711db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-19-2025\n",
      "08_46\n"
     ]
    }
   ],
   "source": [
    "# year month day\n",
    "dayTime = datetime.datetime.now().strftime('%m-%d-%Y')\n",
    "# Minutes and seconds\n",
    "hourTime = datetime.datetime.now().strftime('%H_%M')\n",
    "print(dayTime + '\\n' + hourTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57644ac0-5e16-488f-b216-f7a063a4d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp -r /kaggle/input/privatedata/* /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e89bab80-0600-4453-b3e3-6f4b06b154ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5b6ceef-4199-4939-91ac-40cca3164afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baqer\\Desktop\\V2X_CNN_All\\Scenario36_64-Beams\\Main_Folder//saved_folder//03-19-2025_08_46\n"
     ]
    }
   ],
   "source": [
    "pwd = os.getcwd() + '//' + 'saved_folder' + '//' + dayTime + '_' + hourTime\n",
    "print(pwd)\n",
    "# Determine whether the folder already exists\n",
    "isExists = os.path.exists(pwd)\n",
    "if not isExists:\n",
    "    os.makedirs(pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ac7b204-1037-4e19-aede-29fc74a77f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = pwd + '//' + 'saved_analysis_files'\n",
    "checkpoint_directory = pwd + '//' + 'checkpoint'\n",
    "\n",
    "isExists = os.path.exists(save_directory)\n",
    "if not isExists:\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "isExists = os.path.exists(checkpoint_directory)\n",
    "if not isExists:\n",
    "    os.makedirs(checkpoint_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0df101b-47ed-4462-bc61-1720d774bd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% | 26% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% | 27% |\n"
     ]
    }
   ],
   "source": [
    "# !pip install GPUtil\n",
    "\n",
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3fe4f11-fc5e-462c-8666-89ae4c8d803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e92a756-d926-4603-aee7-929994ae9f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Device Count: 1\n",
      "CUDA Device Name: NVIDIA GeForce RTX 2080 Super with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
    "print(\"CUDA Device Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ca44b03-fe8a-461c-86a8-b4a638499782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06b43a26-048b-4116-8e9f-240336096429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "821ea9f2-404f-4abb-85e3-1dca5c49488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd04ffc8-6284-4b9f-9142-468df5b9f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(root, shuffle=False, nat_sort=False):\n",
    "    f = pd.read_csv(root)\n",
    "    data_samples = []\n",
    "    pred_val = []\n",
    "    for idx, row in f.iterrows():\n",
    "        data = list(row.values[1:])\n",
    "        # print(data)\n",
    "        data_samples.append(data)\n",
    "\n",
    "    return data_samples\n",
    "\n",
    "\n",
    "class DataFeed(Dataset):\n",
    "    '''\n",
    "    A class retrieving a tuple of (image,label). It can handle the case\n",
    "    of empty classes (empty folders).\n",
    "    '''\n",
    "    def __init__(self, image_dir, pos_dir, lidar_dir, nat_sort = False, num_points=15000, image_transform=None, pos_transform = None, init_shuflle = True):\n",
    "        self.root1 = image_dir\n",
    "        self.root2 = pos_dir\n",
    "        self.root3 = lidar_dir\n",
    "\n",
    "        self.num_points = num_points\n",
    "\n",
    "        self.samples1 = create_samples(self.root1, shuffle=init_shuflle, nat_sort=nat_sort)\n",
    "        self.samples2 = create_samples(self.root2, shuffle=init_shuflle, nat_sort=nat_sort)\n",
    "        self.samples3 = create_samples(self.root3, shuffle=init_shuflle, nat_sort=nat_sort)\n",
    "        self.transform1 = image_transform\n",
    "        self.transform2 = pos_transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample1 = self.samples1[idx]\n",
    "        img = io.imread(sample1[0])\n",
    "        if self.transform1:\n",
    "            img = self.transform1(img)\n",
    "        label = sample1[1]\n",
    "\n",
    "        ################################\n",
    "        sample2 = self.samples2[idx]\n",
    "\n",
    "        pos_val = sample2[:1]\n",
    "        pos_val = ast.literal_eval(pos_val[0])\n",
    "        pos_val = np.asarray(pos_val)\n",
    "        ################################\n",
    "        sample3 = self.samples3[idx]\n",
    "        df = pd.read_csv(sample3[0])\n",
    "        # Extract the columns of interest\n",
    "        x = df[' X (mm)'] / 1000  # Convert to meters\n",
    "        y = df[' Y (mm)'] / 1000\n",
    "        z = df[' Z (mm)'] / 1000\n",
    "        points = np.column_stack((x.values, y.values, z.values))\n",
    "        if points.shape[0] < self.num_points:\n",
    "            points = np.pad(points, ((0, self.num_points - points.shape[0]), (0, 0)), mode='constant')\n",
    "        elif points.shape[0] > self.num_points:\n",
    "            indices = np.random.choice(points.shape[0], self.num_points, replace=False)\n",
    "            points = points[indices]\n",
    "\n",
    "        points = torch.tensor(points, dtype=torch.float32)\n",
    "\n",
    "        # pos_centers = sample2[1:2]\n",
    "        # pos_centers = np.asarray(pos_centers)\n",
    "\n",
    "        return ([img, pos_val, points.T], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b84b0ffc-a41b-4e38-a2ab-3ba9161552e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transform\n",
    "img_resize = transf.Resize((224, 224))\n",
    "img_norm = transf.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "image_proc_pipe = transf.Compose(\n",
    "    [transf.ToPILImage(),\n",
    "     img_resize,\n",
    "     transf.ToTensor(),\n",
    "     img_norm]\n",
    ")\n",
    "\n",
    "\n",
    "#POS transform\n",
    "pos_proc_pipe = transf.Compose(\n",
    "    [\n",
    "        transf.ToTensor()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18635b3a-7304-4758-8b8a-000e737f913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train_dir = './scenario36_64_img_beam_train.csv'\n",
    "image_val_dir = './scenario36_64_img_beam_val.csv'\n",
    "\n",
    "pos_train_dir = './scenario36_64_pos_beam_train.csv'\n",
    "pos_val_dir = './scenario36_64_pos_beam_val.csv'\n",
    "\n",
    "lidar_train_dir = './scenario36_64_lidar_beam_train.csv'\n",
    "lidar_val_dir = './scenario36_64_lidar_beam_val.csv'\n",
    "\n",
    "train_loader = DataLoader(DataFeed(image_train_dir, pos_train_dir, lidar_train_dir, image_transform=image_proc_pipe),\n",
    "                          batch_size=batch_size,\n",
    "                          #num_workers=8,\n",
    "                          shuffle=False)\n",
    "val_loader = DataLoader(DataFeed(image_val_dir, pos_val_dir, lidar_train_dir, image_transform=image_proc_pipe),\n",
    "                        batch_size=val_batch_size,\n",
    "                        #num_workers=8,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3403c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "                        ####PointTransformerV3####\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from torchsummary import summary\n",
    "\n",
    "class InputLayer(nn.Module):\n",
    "    \"\"\"Input Layer to accept input point cloud data.\"\"\"\n",
    "    def __init__(self, k=3):\n",
    "        super(InputLayer, self).__init__()\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure the input shape is (batch_size, num_points, channels)\n",
    "        return x.transpose(1, 2)  # Change shape to (batch_size, channels, num_points)\n",
    "\n",
    "\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    \"\"\"Embedding Layer for dimensionality reduction.\"\"\"\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.conv = nn.Conv1d(input_channels, output_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x should be in shape (batch_size, channels, num_points)\n",
    "        x = x.transpose(1, 2)  # Transpose to (batch_size, channels, num_points)\n",
    "        return F.relu(self.conv(x))  # Applies a 1x1 convolution\n",
    "\n",
    "\n",
    "class EncoderStage(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.3):\n",
    "        super(EncoderStage, self).__init__()\n",
    "        self.cpe = nn.Conv1d(in_channels, out_channels, kernel_size=1)  # CPE\n",
    "        self.norm = nn.BatchNorm1d(out_channels)  # Normalization\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=out_channels, num_heads=8)  # Attention\n",
    "        self.dropout_att = nn.Dropout(dropout_rate)  # Dropout after attention\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(out_channels, out_channels),  # MLP layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),  # Dropout after first MLP layer\n",
    "            nn.Linear(out_channels, out_channels)   # Another MLP layer\n",
    "        )\n",
    "        self.dropout_mlp = nn.Dropout(dropout_rate)  # Dropout after second MLP layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply CPE\n",
    "        identity = x  # Save the input for residual connection\n",
    "        x = F.relu(self.cpe(x))\n",
    "        x = self.norm(x)\n",
    "\n",
    "        # Prepare for Attention mechanism\n",
    "        x_att = x.transpose(2, 1)  # Shape change for attention\n",
    "        x_att, _ = self.attention(x_att, x_att, x_att)  # Attention output\n",
    "        x_att = self.dropout_att(x_att)  # Apply dropout\n",
    "\n",
    "        x_att = x_att.transpose(2, 1)  # Transpose back\n",
    "        x = x + x_att  # Skip connection\n",
    "\n",
    "        # MLP\n",
    "        b, c, p = x.size()\n",
    "        x = x.view(b * p, c)  # Flatten for MLP\n",
    "        x = self.mlp(x)  # Apply MLP\n",
    "        x = self.dropout_mlp(x)  # Apply dropout after MLP\n",
    "\n",
    "        # Reshape back to (B, out_channels, num_points)\n",
    "        output_channels = x.size(1)\n",
    "        x = x.view(b, output_channels, p)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SerializedPoolingLayer(nn.Module):\n",
    "    \"\"\"Serialized Pooling Layer for dimensionality reduction.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(SerializedPoolingLayer, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool1d(x, kernel_size=2)  # Average pooling\n",
    "\n",
    "\n",
    "class PointTransformerV3(nn.Module):\n",
    "    \"\"\"Main Point Transformer V3 for Classification.\"\"\"\n",
    "    def __init__(self, num_classes,  enc_depths=[64, 128,256,512], dropout_rate=0.1):\n",
    "        super(PointTransformerV3, self).__init__()\n",
    "\n",
    "        # Input and embedding\n",
    "        self.input_layer = InputLayer()\n",
    "        self.embedding = EmbeddingLayer(input_channels=3, output_channels=enc_depths[0])  # Initial embedding layer\n",
    "\n",
    "        # Encoder stages\n",
    "        self.encoders = nn.ModuleList()\n",
    "        in_channels = enc_depths[0]\n",
    "        for out_channels in enc_depths:\n",
    "            self.encoders.append(EncoderStage(in_channels, out_channels, dropout_rate=dropout_rate))\n",
    "            in_channels = out_channels\n",
    "\n",
    "        # Serialized pooling\n",
    "        self.serialized_pooling = SerializedPoolingLayer()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(enc_depths[-1], 128)  # Input size from enc_depths[-1]\n",
    "        self.fc2 = nn.Linear(128, 64)  # Intermediate layer\n",
    "        self.fc3 = nn.Linear(64, 128)  # Output layer for 65 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input layer\n",
    "        x = self.input_layer(x)\n",
    "\n",
    "        # Embedding layer\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # Pass through encoder stages\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "\n",
    "        # Serialized pooling\n",
    "        x = self.serialized_pooling(x)\n",
    "\n",
    "        # Global feature extraction\n",
    "        x = torch.max(x, dim=2)[0]  # Global max pooling across points\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class FusionModel(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(FusionModel, self).__init__()\n",
    "        self.nclass = num_classes\n",
    "        self.nf = num_features\n",
    "\n",
    "        # Using MaxViT from timm for image feature extraction\n",
    "        self.maxvit = timm.create_model('maxvit_tiny_tf_224.in1k', pretrained=True)\n",
    "        self.maxvit_fc = nn.Linear(self.maxvit.num_features, 128)\n",
    "\n",
    "        # Using PointTransformerV3 for point cloud feature extraction\n",
    "        self.point_transformer = PointTransformerV3(num_classes=self.nclass)\n",
    "\n",
    "        # MLP for the positional data (additional features)\n",
    "        self.positional_fc = nn.Sequential(\n",
    "            nn.Linear(self.nf, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128)\n",
    "            \n",
    "        )\n",
    "\n",
    "        # Final fully connected layers for fusion\n",
    "        self.fc1 = nn.Linear(128 + 128 + 128, 256)  # Image + PointCloud + Positional\n",
    "        self.fc2 = nn.Linear(256, self.nclass)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "       \n",
    "        # Extract image data and pass it through MaxViT\n",
    "        image_data = inputs[0]\n",
    "        x_image = self.maxvit.forward_features(image_data)\n",
    "        x_image = x_image.mean(dim=[2, 3])  # Global average pooling\n",
    "        x_image = self.maxvit_fc(x_image)\n",
    "\n",
    "        # Extract point cloud data and pass it through PointTransformerV3\n",
    "        point_cloud_data = inputs[2]\n",
    "        x_point_cloud = self.point_transformer(point_cloud_data)\n",
    "\n",
    "        # Process positional data (additional features)\n",
    "        positional_data = inputs[1]\n",
    "        y = self.positional_fc(positional_data.reshape([-1, self.nf]))\n",
    "\n",
    "        # Concatenate features from image, point cloud, and positional data\n",
    "        x = torch.cat([x_image, x_point_cloud, y], dim=1)\n",
    "\n",
    "        # Pass through fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FusionModel(num_features=input_size, num_classes=output_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04a3bcb6-f829-4143-acbc-c67cbd5ca2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```````````````````````````````````````````````````````\n",
      "Training size is 1\n",
      "Epoch No. 1\n",
      "Training-Batch No.100\n",
      "Loss = 4.49623966217041\n",
      "Training-Batch No.200\n",
      "Loss = 3.918278217315674\n",
      "Training-Batch No.300\n",
      "Loss = 4.962121486663818\n",
      "Training-Batch No.400\n",
      "Loss = 3.248656749725342\n",
      "Training-Batch No.500\n",
      "Loss = 4.278253555297852\n",
      "Training-Batch No.600\n",
      "Loss = 3.7459192276000977\n",
      "Training-Batch No.700\n",
      "Loss = 2.783893346786499\n",
      "Training-Batch No.800\n",
      "Loss = 4.446086883544922\n",
      "Training-Batch No.900\n",
      "Loss = 3.133831262588501\n",
      "Training-Batch No.1000\n",
      "Loss = 3.8383102416992188\n",
      "Training-Batch No.1100\n",
      "Loss = 2.6668524742126465\n",
      "Training-Batch No.1200\n",
      "Loss = 3.154496192932129\n",
      "Training-Batch No.1300\n",
      "Loss = 2.3489136695861816\n",
      "Training-Batch No.1400\n",
      "Loss = 4.294672966003418\n",
      "Training-Batch No.1500\n",
      "Loss = 4.383076190948486\n",
      "Training-Batch No.1600\n",
      "Loss = 3.645030975341797\n",
      "Training-Batch No.1700\n",
      "Loss = 3.820612907409668\n",
      "Training-Batch No.1800\n",
      "Loss = 4.410951614379883\n",
      "Training-Batch No.1900\n",
      "Loss = 3.248305559158325\n",
      "Training-Batch No.2000\n",
      "Loss = 3.0459628105163574\n",
      "Training-Batch No.2100\n",
      "Loss = 3.612476348876953\n",
      "Training-Batch No.2200\n",
      "Loss = 1.4069054126739502\n",
      "Training-Batch No.2300\n",
      "Loss = 4.388782501220703\n",
      "Training-Batch No.2400\n",
      "Loss = 3.512497663497925\n",
      "Training-Batch No.2500\n",
      "Loss = 2.987755060195923\n",
      "Training-Batch No.2600\n",
      "Loss = 3.7042205333709717\n",
      "Training-Batch No.2700\n",
      "Loss = 3.8254294395446777\n",
      "Training-Batch No.2800\n",
      "Loss = 2.122600793838501\n",
      "Training-Batch No.2900\n",
      "Loss = 2.970109462738037\n",
      "Training-Batch No.3000\n",
      "Loss = 4.508852005004883\n",
      "Training-Batch No.3100\n",
      "Loss = 3.1686863899230957\n",
      "Training-Batch No.3200\n",
      "Loss = 3.493680000305176\n",
      "Training-Batch No.3300\n",
      "Loss = 4.207786560058594\n",
      "Training-Batch No.3400\n",
      "Loss = 3.6098544597625732\n",
      "Training-Batch No.3500\n",
      "Loss = 72.72176361083984\n",
      "Training-Batch No.3600\n",
      "Loss = 9.269946098327637\n",
      "Training-Batch No.3700\n",
      "Loss = 6.770875930786133\n",
      "Epoch 1 Training Loss: 14.7722\n",
      "Start Training and Validation\n",
      "total training examples are 7440\n",
      "Training_size 1--No. of skipped batchess 0\n",
      "Average Top-1 accuracy 0.1385752688172043\n",
      "Average Top-3 accuracy 0.2318548387096774\n",
      "Average Top-5 accuracy 0.2884408602150538\n",
      "Average Top-7 accuracy 0.3407258064516129\n",
      "Average Top-9 accuracy 0.3959677419354839\n",
      "Average Top-11 accuracy 0.43185483870967745\n",
      "Average Top-13 accuracy 0.4685483870967742\n",
      "Average Top-15 accuracy 0.5005376344086021\n",
      "current acc 0.1385752688172043\n",
      "best acc 0\n",
      "Saving the best model\n",
      "updated best acc 0.1385752688172043\n",
      "Saving the predicted value in a csv file\n"
     ]
    }
   ],
   "source": [
    "    val_acc = []\n",
    "\n",
    "#with cuda.device(0):\n",
    "    top_1 = np.zeros( (1,len(train_size)) )\n",
    "    top_3 = np.zeros( (1,len(train_size)) )\n",
    "    top_5 = np.zeros( (1,len(train_size)) )\n",
    "    top_7 = np.zeros( (1,len(train_size)) )\n",
    "    top_9 = np.zeros( (1,len(train_size)) )\n",
    "    top_11 = np.zeros( (1,len(train_size)) )\n",
    "    top_13 = np.zeros( (1,len(train_size)) )\n",
    "    top_15 = np.zeros( (1,len(train_size)) )\n",
    "    acc_loss = 0\n",
    "    itr = []\n",
    "    for idx, n in enumerate(train_size):\n",
    "        print('```````````````````````````````````````````````````````')\n",
    "        print('Training size is {}'.format(n))\n",
    "        # Build the network:\n",
    "        net = model.cuda()\n",
    "        layers = list(net.children())\n",
    "\n",
    "        #  Optimization parameters:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        opt = optimizer.Adam(net.parameters(), lr=lr, weight_decay=decay)\n",
    "        LR_sch = optimizer.lr_scheduler.MultiStepLR(opt, [15,25,40], gamma=0.1, last_epoch=-1)\n",
    "\n",
    "        count = 0\n",
    "        running_loss = []\n",
    "        running_top1_acc = []\n",
    "        running_top3_acc = []\n",
    "        running_top5_acc = []\n",
    "        running_top7_acc = []\n",
    "        running_top9_acc = []\n",
    "        running_top11_acc = []\n",
    "        running_top13_acc = []\n",
    "        running_top15_acc = []\n",
    "\n",
    "        best_accuracy = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print('Epoch No. ' + str(epoch + 1))\n",
    "            skipped_batches = 0\n",
    "            epoch_train_loss = 0  # To track the training loss for the epoch # Added\n",
    "            for tr_count, (pos_data, beam_val) in enumerate(train_loader):\n",
    "                net.train()\n",
    "                data = [pos_data[0], pos_data[1].type(torch.Tensor), pos_data[2].type(torch.Tensor)]\n",
    "                label = beam_val.type(torch.LongTensor)\n",
    "                x = [data[0].cuda(), data[1].cuda(), data[2].cuda()]\n",
    "                #print(\"x size\", x.size())\n",
    "                opt.zero_grad()\n",
    "                label = label.cuda()\n",
    "                #print(\"label size\", label.size())\n",
    "                # print(x.shape)\n",
    "                out = net.forward(x)\n",
    "                # print(out.shape, label.shape)\n",
    "                loss = criterion(out, label)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                batch_loss = loss.item()\n",
    "                acc_loss += batch_loss\n",
    "                epoch_train_loss += batch_loss  # Accumulate batch loss for the epoch # Added\n",
    "                count += 1\n",
    "                if np.mod(count, 100) == 0:\n",
    "                    print('Training-Batch No.' + str(count))\n",
    "                    running_loss.append(batch_loss)  # running_loss.append()\n",
    "                    itr.append(count)\n",
    "                    print('Loss = ' + str(running_loss[-1]))\n",
    "\n",
    "            epoch_train_loss /= len(train_loader)  # Calculate average training loss for the epoch # Added\n",
    "            print(f'Epoch {epoch + 1} Training Loss: {epoch_train_loss:.4f}') # Added\n",
    "            \n",
    "            print('Start Training and Validation')\n",
    "            ave_top1_acc = 0\n",
    "            ave_top3_acc = 0\n",
    "            ave_top5_acc = 0\n",
    "            ave_top7_acc = 0\n",
    "            ave_top9_acc = 0\n",
    "            ave_top11_acc = 0\n",
    "            ave_top13_acc = 0\n",
    "            ave_top15_acc = 0\n",
    "            ind_ten = t.as_tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], device='cuda:0')\n",
    "            top1_pred_out = []\n",
    "            top3_pred_out = []\n",
    "            top5_pred_out = []\n",
    "            top7_pred_out = []\n",
    "            top9_pred_out = []\n",
    "            top11_pred_out = []\n",
    "            top13_pred_out = []\n",
    "            top15_pred_out = []\n",
    "            total_count = 0\n",
    "\n",
    "            gt_beam = []\n",
    "            for val_count, (pos_data, beam_val) in enumerate(val_loader):\n",
    "                net.eval()\n",
    "                data = [pos_data[0], pos_data[1].type(torch.Tensor), pos_data[2].type(torch.Tensor)]\n",
    "                label = beam_val.type(torch.LongTensor)\n",
    "                x = [data[0].cuda(), data[1].cuda(), data[2].cuda()]\n",
    "                #print(\"x size\", x.size())\n",
    "                opt.zero_grad()\n",
    "                labels = label.cuda()\n",
    "                \n",
    "                # val_batch_loss = criterion(out, labels).item()  # Calculate validation loss for the batch # Added\n",
    "                # val_loss += val_batch_loss  # Accumulate batch loss for the epoch # Added\n",
    "                \n",
    "                gt_beam.append(labels.detach().cpu().numpy()[0].tolist())\n",
    "                total_count += labels.size(0)\n",
    "                out = net.forward(x)\n",
    "                _, top_1_pred = t.max(out, dim=1)\n",
    "                top1_pred_out.append(top_1_pred.detach().cpu().numpy()[0].tolist())\n",
    "                sorted_out = t.argsort(out, dim=1, descending=True)\n",
    "\n",
    "                top_3_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:3])\n",
    "                top3_pred_out.append(top_3_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                top_5_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:5])\n",
    "                top5_pred_out.append(top_5_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                top_7_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:7])\n",
    "                top7_pred_out.append(top_7_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                top_9_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:9])\n",
    "                top9_pred_out.append(top_9_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                top_11_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:11])\n",
    "                top11_pred_out.append(top_11_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                top_13_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:13])\n",
    "                top13_pred_out.append(top_13_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                top_15_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:15])\n",
    "                top15_pred_out.append(top_15_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "                reshaped_labels = labels.reshape((labels.shape[0], 1))\n",
    "                tiled_3_labels = reshaped_labels.repeat(1, 3)\n",
    "                tiled_5_labels = reshaped_labels.repeat(1, 5)\n",
    "                tiled_7_labels = reshaped_labels.repeat(1, 7)\n",
    "                tiled_9_labels = reshaped_labels.repeat(1, 9)\n",
    "                tiled_11_labels = reshaped_labels.repeat(1, 11)\n",
    "                tiled_13_labels = reshaped_labels.repeat(1, 13)\n",
    "                tiled_15_labels = reshaped_labels.repeat(1, 15)\n",
    "\n",
    "                batch_top1_acc = t.sum(top_1_pred == labels, dtype=t.float32)\n",
    "                batch_top3_acc = t.sum(top_3_pred == tiled_3_labels, dtype=t.float32)\n",
    "                batch_top5_acc = t.sum(top_5_pred == tiled_5_labels, dtype=t.float32)\n",
    "                batch_top7_acc = t.sum(top_7_pred == tiled_7_labels, dtype=t.float32)\n",
    "                batch_top9_acc = t.sum(top_9_pred == tiled_9_labels, dtype=t.float32)\n",
    "                batch_top11_acc = t.sum(top_11_pred == tiled_11_labels, dtype=t.float32)\n",
    "                batch_top13_acc = t.sum(top_13_pred == tiled_13_labels, dtype=t.float32)\n",
    "                batch_top15_acc = t.sum(top_15_pred == tiled_15_labels, dtype=t.float32)\n",
    "\n",
    "                ave_top1_acc += batch_top1_acc.item()\n",
    "                ave_top3_acc += batch_top3_acc.item()\n",
    "                ave_top5_acc += batch_top5_acc.item()\n",
    "                ave_top7_acc += batch_top7_acc.item()\n",
    "                ave_top9_acc += batch_top9_acc.item()\n",
    "                ave_top11_acc += batch_top11_acc.item()\n",
    "                ave_top13_acc += batch_top13_acc.item()\n",
    "                ave_top15_acc += batch_top15_acc.item()\n",
    "\n",
    "            # val_loss /= len(val_loader)  # Calculate average validation loss for the epoch # Added\n",
    "            # print(f'Epoch {epoch + 1} Validation Loss: {val_loss:.4f}') # Added\n",
    "            \n",
    "            print(\"total training examples are\", total_count)\n",
    "            running_top1_acc.append(ave_top1_acc / total_count)  # (batch_size * (count_2 + 1)) )\n",
    "            running_top3_acc.append(ave_top3_acc / total_count)\n",
    "            running_top5_acc.append(ave_top5_acc / total_count)\n",
    "            running_top7_acc.append(ave_top7_acc / total_count)\n",
    "            running_top9_acc.append(ave_top9_acc / total_count)\n",
    "            running_top11_acc.append(ave_top11_acc / total_count)\n",
    "            running_top13_acc.append(ave_top13_acc / total_count)\n",
    "            running_top15_acc.append(ave_top15_acc / total_count)\n",
    "\n",
    "            print('Training_size {}--No. of skipped batchess {}'.format(n,skipped_batches))\n",
    "            print('Average Top-1 accuracy {}'.format( running_top1_acc[-1]))\n",
    "            print('Average Top-3 accuracy {}'.format( running_top3_acc[-1]))\n",
    "            print('Average Top-5 accuracy {}'.format( running_top5_acc[-1]))\n",
    "            print('Average Top-7 accuracy {}'.format( running_top7_acc[-1]))\n",
    "            print('Average Top-9 accuracy {}'.format( running_top9_acc[-1]))\n",
    "            print('Average Top-11 accuracy {}'.format( running_top11_acc[-1]))\n",
    "            print('Average Top-13 accuracy {}'.format( running_top13_acc[-1]))\n",
    "            print('Average Top-15 accuracy {}'.format( running_top15_acc[-1]))\n",
    "\n",
    "            cur_accuracy  = running_top1_acc[-1]\n",
    "\n",
    "            print(\"current acc\", cur_accuracy)\n",
    "            print(\"best acc\", best_accuracy)\n",
    "            if cur_accuracy > best_accuracy:\n",
    "                print(\"Saving the best model\")\n",
    "                net_name = checkpoint_directory  + '//' +  'fused_transfomer_beam_pred'\n",
    "                t.save(net.state_dict(), net_name)\n",
    "                best_accuracy =  cur_accuracy\n",
    "            print(\"updated best acc\", best_accuracy)\n",
    "\n",
    "\n",
    "            print(\"Saving the predicted value in a csv file\")\n",
    "            file_to_save = f'{save_directory}//topk_fused_val_after_{epoch+1}th_epoch.csv'\n",
    "            indx = np.arange(1, len(top1_pred_out)+1, 1)\n",
    "            df1 = pd.DataFrame()\n",
    "            df1['index'] = indx\n",
    "            df1['link_status'] = gt_beam\n",
    "            df1['top1_pred'] = top1_pred_out\n",
    "            df1['top3_pred'] = top3_pred_out\n",
    "            df1['top5_pred'] = top5_pred_out\n",
    "            df1['top7_pred'] = top7_pred_out\n",
    "            df1['top9_pred'] = top9_pred_out\n",
    "            df1['top11_pred'] = top11_pred_out\n",
    "            df1['top13_pred'] = top13_pred_out\n",
    "            df1['top15_pred'] = top15_pred_out\n",
    "            df1.to_csv(file_to_save, index=False)\n",
    "\n",
    "            LR_sch.step()\n",
    "\n",
    "        top_1[0,idx] = running_top1_acc[-1]\n",
    "        top_3[0,idx] = running_top3_acc[-1]\n",
    "        top_5[0,idx] = running_top5_acc[-1]\n",
    "        top_7[0,idx] = running_top7_acc[-1]\n",
    "        top_9[0,idx] = running_top9_acc[-1]\n",
    "        top_11[0,idx] = running_top11_acc[-1]\n",
    "        top_13[0,idx] = running_top13_acc[-1]\n",
    "        top_15[0,idx] = running_top15_acc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03ff9cf6-7db2-4b5e-b057-975b3ff860dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Validation\n",
      "total examples are 7440\n",
      "Training_size 1--No. of skipped batchess 0\n",
      "Average Top-1 accuracy 0.1385752688172043\n",
      "Average Top-3 accuracy 0.2318548387096774\n",
      "Average Top-5 accuracy 0.2884408602150538\n",
      "Average Top-7 accuracy 0.3407258064516129\n",
      "Average Top-9 accuracy 0.3959677419354839\n",
      "Average Top-11 accuracy 0.43185483870967745\n",
      "Average Top-13 accuracy 0.4685483870967742\n",
      "Average Top-15 accuracy 0.5005376344086021\n",
      "Saving the predicted value in a csv file\n"
     ]
    }
   ],
   "source": [
    "print('Start Validation')\n",
    "ave_top1_acc = 0\n",
    "ave_top3_acc = 0\n",
    "ave_top5_acc = 0\n",
    "ave_top7_acc = 0\n",
    "ave_top9_acc = 0\n",
    "ave_top11_acc = 0\n",
    "ave_top13_acc = 0\n",
    "ave_top15_acc = 0\n",
    "ind_ten = t.as_tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], device='cuda:0')\n",
    "top1_pred_out = []\n",
    "top3_pred_out = []\n",
    "top5_pred_out = []\n",
    "top7_pred_out = []\n",
    "top9_pred_out = []\n",
    "top11_pred_out = []\n",
    "top13_pred_out = []\n",
    "top15_pred_out = []\n",
    "running_top1_acc = []\n",
    "running_top3_acc = []\n",
    "running_top5_acc = []\n",
    "running_top7_acc = []\n",
    "running_top9_acc = []\n",
    "running_top11_acc = []\n",
    "running_top13_acc = []\n",
    "running_top15_acc = []\n",
    "total_count = 0\n",
    "\n",
    "gt_beam = []\n",
    "\n",
    "for val_count, (pos_data, beam_val) in enumerate(val_loader):\n",
    "    net.eval()\n",
    "    data = [pos_data[0], pos_data[1].type(torch.Tensor), pos_data[2].type(torch.Tensor)]\n",
    "    label = beam_val.type(torch.LongTensor)\n",
    "    x = [data[0].cuda(), data[1].cuda(), data[2].cuda()]\n",
    "    #print(\"x size\", x.size())\n",
    "    opt.zero_grad()\n",
    "    labels = label.cuda()\n",
    "\n",
    "    gt_beam.append(labels.detach().cpu().numpy()[0].tolist())\n",
    "    total_count += labels.size(0)\n",
    "    out = net.forward(x)\n",
    "    _, top_1_pred = t.max(out, dim=1)\n",
    "    top1_pred_out.append(top_1_pred.detach().cpu().numpy()[0].tolist())\n",
    "    sorted_out = t.argsort(out, dim=1, descending=True)\n",
    "\n",
    "    top_3_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:3])\n",
    "    top3_pred_out.append(top_3_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "    top_5_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:5])\n",
    "    top5_pred_out.append(top_5_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "    top_7_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:7])\n",
    "    top7_pred_out.append(top_7_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "    top_9_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:9])\n",
    "    top9_pred_out.append(top_9_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "    top_11_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:11])\n",
    "    top11_pred_out.append(top_11_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "    top_13_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:13])\n",
    "    top13_pred_out.append(top_13_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "    top_15_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:15])\n",
    "    top15_pred_out.append(top_15_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "    reshaped_labels = labels.reshape((labels.shape[0], 1))\n",
    "    tiled_3_labels = reshaped_labels.repeat(1, 3)\n",
    "    tiled_5_labels = reshaped_labels.repeat(1, 5)\n",
    "    tiled_7_labels = reshaped_labels.repeat(1, 7)\n",
    "    tiled_9_labels = reshaped_labels.repeat(1, 9)\n",
    "    tiled_11_labels = reshaped_labels.repeat(1, 11)\n",
    "    tiled_13_labels = reshaped_labels.repeat(1, 13)\n",
    "    tiled_15_labels = reshaped_labels.repeat(1, 15)\n",
    "\n",
    "    batch_top1_acc = t.sum(top_1_pred == labels, dtype=t.float32)\n",
    "    batch_top3_acc = t.sum(top_3_pred == tiled_3_labels, dtype=t.float32)\n",
    "    batch_top5_acc = t.sum(top_5_pred == tiled_5_labels, dtype=t.float32)\n",
    "    batch_top7_acc = t.sum(top_7_pred == tiled_7_labels, dtype=t.float32)\n",
    "    batch_top9_acc = t.sum(top_9_pred == tiled_9_labels, dtype=t.float32)\n",
    "    batch_top11_acc = t.sum(top_11_pred == tiled_11_labels, dtype=t.float32)\n",
    "    batch_top13_acc = t.sum(top_13_pred == tiled_13_labels, dtype=t.float32)\n",
    "    batch_top15_acc = t.sum(top_15_pred == tiled_15_labels, dtype=t.float32)\n",
    "\n",
    "    ave_top1_acc += batch_top1_acc.item()\n",
    "    ave_top3_acc += batch_top3_acc.item()\n",
    "    ave_top5_acc += batch_top5_acc.item()\n",
    "    ave_top7_acc += batch_top7_acc.item()\n",
    "    ave_top9_acc += batch_top9_acc.item()\n",
    "    ave_top11_acc += batch_top11_acc.item()\n",
    "    ave_top13_acc += batch_top13_acc.item()\n",
    "    ave_top15_acc += batch_top15_acc.item()\n",
    "\n",
    "print(\"total examples are\", total_count)\n",
    "running_top1_acc.append(ave_top1_acc / total_count)  # (batch_size * (count_2 + 1)) )\n",
    "running_top3_acc.append(ave_top3_acc / total_count)\n",
    "running_top5_acc.append(ave_top5_acc / total_count)\n",
    "running_top7_acc.append(ave_top7_acc / total_count)\n",
    "running_top9_acc.append(ave_top9_acc / total_count)\n",
    "running_top11_acc.append(ave_top11_acc / total_count)\n",
    "running_top13_acc.append(ave_top13_acc / total_count)\n",
    "running_top15_acc.append(ave_top15_acc / total_count)\n",
    "\n",
    "print('Training_size {}--No. of skipped batchess {}'.format(n,skipped_batches))\n",
    "print('Average Top-1 accuracy {}'.format( running_top1_acc[-1]))\n",
    "print('Average Top-3 accuracy {}'.format( running_top3_acc[-1]))\n",
    "print('Average Top-5 accuracy {}'.format( running_top5_acc[-1]))\n",
    "print('Average Top-7 accuracy {}'.format( running_top7_acc[-1]))\n",
    "print('Average Top-9 accuracy {}'.format( running_top9_acc[-1]))\n",
    "print('Average Top-11 accuracy {}'.format( running_top11_acc[-1]))\n",
    "print('Average Top-13 accuracy {}'.format( running_top13_acc[-1]))\n",
    "print('Average Top-15 accuracy {}'.format( running_top15_acc[-1]))\n",
    "\n",
    "print(\"Saving the predicted value in a csv file\")\n",
    "file_to_save = f'{save_directory}//best_epoch_eval.csv'\n",
    "\n",
    "indx = np.arange(1, len(top1_pred_out)+1, 1)\n",
    "df2 = pd.DataFrame()\n",
    "df2['index'] = indx\n",
    "df2['link_status'] = gt_beam  # Add the link_status column\n",
    "\n",
    "df2['top1_pred'] = top1_pred_out\n",
    "df2['top3_pred'] = top3_pred_out\n",
    "df2['top5_pred'] = top5_pred_out\n",
    "df2['top7_pred'] = top7_pred_out\n",
    "df2['top9_pred'] = top9_pred_out\n",
    "df2['top11_pred'] = top11_pred_out\n",
    "df2['top13_pred'] = top13_pred_out\n",
    "df2['top15_pred'] = top15_pred_out\n",
    "df2.to_csv(file_to_save, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91aaa162-cd05-4e4b-a741-1dc0ac7ed11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "368f8c6d-a87e-495f-b3fa-0050e277a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model checkpoint\n",
    "image_test_dir = './scenario36_64_img_beam_test.csv'\n",
    "pos_test_dir = './scenario36_64_pos_beam_test.csv'\n",
    "lidar_test_dir = './scenario36_64_lidar_beam_test.csv'\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv(image_test_dir)\n",
    "\n",
    "# Extract the 'unit1_pwr1_best-beam' data and convert it to a list\n",
    "link_status_data = test_data['original_unit1_pwr3_best-beam'].tolist()\n",
    "org = test_data['original_index'].tolist()\n",
    "pwr_60ghz = test_data['original_unit1_pwr3'].tolist()\n",
    "\n",
    "checkpoint_path = f'{checkpoint_directory}/fused_transfomer_beam_pred'\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "model.eval()\n",
    "net = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58af44d8-f685-46aa-8b28-d8eab05bd2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(DataFeed(image_test_dir, pos_test_dir,lidar_test_dir, image_transform=image_proc_pipe),\n",
    "                            batch_size=val_batch_size,\n",
    "                            #num_workers=8,\n",
    "                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36a16aa7-c94b-4bb5-88a9-ab04711bdcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Testing\n",
      "total test examples are 2480\n",
      "Training_size 1--No. of skipped batchess 0\n",
      "Average Top-1 accuracy 0.14637096774193548\n",
      "Average Top-3 accuracy 0.23911290322580644\n",
      "Average Top-5 accuracy 0.29274193548387095\n",
      "Average Top-7 accuracy 0.34596774193548385\n",
      "Average Top-9 accuracy 0.39838709677419354\n",
      "Average Top-11 accuracy 0.43709677419354837\n",
      "Average Top-13 accuracy 0.4717741935483871\n",
      "Average Top-15 accuracy 0.4963709677419355\n",
      "Saving the predicted value in a csv file\n"
     ]
    }
   ],
   "source": [
    "print('Start Testing')\n",
    "ave_top1_acc = 0\n",
    "ave_top3_acc = 0\n",
    "ave_top5_acc = 0\n",
    "ave_top7_acc = 0\n",
    "ave_top9_acc = 0\n",
    "ave_top11_acc = 0\n",
    "ave_top13_acc = 0\n",
    "ave_top15_acc = 0\n",
    "ind_ten = t.as_tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], device='cuda:0')\n",
    "top1_pred_out = []\n",
    "top3_pred_out = []\n",
    "top5_pred_out = []\n",
    "top7_pred_out = []\n",
    "top9_pred_out = []\n",
    "top11_pred_out = []\n",
    "top13_pred_out = []\n",
    "top15_pred_out = []\n",
    "running_top1_acc = []\n",
    "running_top3_acc = []\n",
    "running_top5_acc = []\n",
    "running_top7_acc = []\n",
    "running_top9_acc = []\n",
    "running_top11_acc = []\n",
    "running_top13_acc = []\n",
    "running_top15_acc = []\n",
    "total_count = 0\n",
    "\n",
    "gt_beam = []\n",
    "\n",
    "for val_count, (pos_data, beam_val) in enumerate(test_loader):\n",
    "    net.eval()\n",
    "    data = [pos_data[0], pos_data[1].type(torch.Tensor),pos_data[2].type(torch.Tensor)]\n",
    "    label = beam_val.type(torch.LongTensor)\n",
    "    x = [data[0].cuda(), data[1].cuda(), data[2].cuda()]\n",
    "    #print(\"x size\", x.size())\n",
    "    opt.zero_grad()\n",
    "    labels = label.cuda()\n",
    "\n",
    "    gt_beam.append(labels.detach().cpu().numpy()[0].tolist())\n",
    "    total_count += labels.size(0)\n",
    "    out = net.forward(x)\n",
    "    _, top_1_pred = t.max(out, dim=1)\n",
    "    top1_pred_out.append(top_1_pred.detach().cpu().numpy()[0].tolist())\n",
    "    sorted_out = t.argsort(out, dim=1, descending=True)\n",
    "\n",
    "    top_3_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:3])\n",
    "    top3_pred_out.append(top_3_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "    top_5_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:5])\n",
    "    top5_pred_out.append(top_5_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "    top_7_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:7])\n",
    "    top7_pred_out.append(top_7_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "    top_9_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:9])\n",
    "    top9_pred_out.append(top_9_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "    top_11_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:11])\n",
    "    top11_pred_out.append(top_11_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "    top_13_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:13])\n",
    "    top13_pred_out.append(top_13_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "    top_15_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:15])\n",
    "    top15_pred_out.append(top_15_pred.detach().cpu().numpy()[0].tolist())\n",
    "\n",
    "    reshaped_labels = labels.reshape((labels.shape[0], 1))\n",
    "    tiled_3_labels = reshaped_labels.repeat(1, 3)\n",
    "    tiled_5_labels = reshaped_labels.repeat(1, 5)\n",
    "    tiled_7_labels = reshaped_labels.repeat(1, 7)\n",
    "    tiled_9_labels = reshaped_labels.repeat(1, 9)\n",
    "    tiled_11_labels = reshaped_labels.repeat(1, 11)\n",
    "    tiled_13_labels = reshaped_labels.repeat(1, 13)\n",
    "    tiled_15_labels = reshaped_labels.repeat(1, 15)\n",
    "\n",
    "    batch_top1_acc = t.sum(top_1_pred == labels, dtype=t.float32)\n",
    "    batch_top3_acc = t.sum(top_3_pred == tiled_3_labels, dtype=t.float32)\n",
    "    batch_top5_acc = t.sum(top_5_pred == tiled_5_labels, dtype=t.float32)\n",
    "    batch_top7_acc = t.sum(top_7_pred == tiled_7_labels, dtype=t.float32)\n",
    "    batch_top9_acc = t.sum(top_9_pred == tiled_9_labels, dtype=t.float32)\n",
    "    batch_top11_acc = t.sum(top_11_pred == tiled_11_labels, dtype=t.float32)\n",
    "    batch_top13_acc = t.sum(top_13_pred == tiled_13_labels, dtype=t.float32)\n",
    "    batch_top15_acc = t.sum(top_15_pred == tiled_15_labels, dtype=t.float32)\n",
    "\n",
    "    ave_top1_acc += batch_top1_acc.item()\n",
    "    ave_top3_acc += batch_top3_acc.item()\n",
    "    ave_top5_acc += batch_top5_acc.item()\n",
    "    ave_top7_acc += batch_top7_acc.item()\n",
    "    ave_top9_acc += batch_top9_acc.item()\n",
    "    ave_top11_acc += batch_top11_acc.item()\n",
    "    ave_top13_acc += batch_top13_acc.item()\n",
    "    ave_top15_acc += batch_top15_acc.item()\n",
    "\n",
    "print(\"total test examples are\", total_count)\n",
    "running_top1_acc.append(ave_top1_acc / total_count)  # (batch_size * (count_2 + 1)) )\n",
    "running_top3_acc.append(ave_top3_acc / total_count)\n",
    "running_top5_acc.append(ave_top5_acc / total_count)\n",
    "running_top7_acc.append(ave_top7_acc / total_count)\n",
    "running_top9_acc.append(ave_top9_acc / total_count)\n",
    "running_top11_acc.append(ave_top11_acc / total_count)\n",
    "running_top13_acc.append(ave_top13_acc / total_count)\n",
    "running_top15_acc.append(ave_top15_acc / total_count)\n",
    "\n",
    "print('Training_size {}--No. of skipped batchess {}'.format(n,skipped_batches))\n",
    "print('Average Top-1 accuracy {}'.format( running_top1_acc[-1]))\n",
    "print('Average Top-3 accuracy {}'.format( running_top3_acc[-1]))\n",
    "print('Average Top-5 accuracy {}'.format( running_top5_acc[-1]))\n",
    "print('Average Top-7 accuracy {}'.format( running_top7_acc[-1]))\n",
    "print('Average Top-9 accuracy {}'.format( running_top9_acc[-1]))\n",
    "print('Average Top-11 accuracy {}'.format( running_top11_acc[-1]))\n",
    "print('Average Top-13 accuracy {}'.format( running_top13_acc[-1]))\n",
    "print('Average Top-15 accuracy {}'.format( running_top15_acc[-1]))\n",
    "\n",
    "print(\"Saving the predicted value in a csv file\")\n",
    "file_to_save = f'{save_directory}//best_epoch_eval_Test.csv'\n",
    "\n",
    "# Extract the 'unit1_pwr1_best-beam' data and convert it to a list\n",
    "# link_status_data = test_data['original_unit1_pwr3_best-beam'].tolist()\n",
    "# org = test_data['original_index'].tolist()\n",
    "# pwr_60ghz = test_data['original_unit1_pwr3'].tolist()\n",
    "\n",
    "indx = test_data.index + 1\n",
    "df2 = pd.DataFrame()\n",
    "df2['index'] = org\n",
    "df2['link_status'] = link_status_data  # Add the link_status column\n",
    "df2['original_unit1_pwr3'] = pwr_60ghz # Add the original_unit1_pwr_60ghz column\n",
    "\n",
    "df2['top1_pred'] = top1_pred_out\n",
    "df2['top3_pred'] = top3_pred_out\n",
    "df2['top5_pred'] = top5_pred_out\n",
    "df2['top7_pred'] = top7_pred_out\n",
    "df2['top9_pred'] = top9_pred_out\n",
    "df2['top11_pred'] = top11_pred_out\n",
    "df2['top13_pred'] = top13_pred_out\n",
    "\n",
    "df2['top15_pred'] = top15_pred_out\n",
    "df2.to_csv(file_to_save, index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6455048,
     "sourceId": 10415160,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6460652,
     "sourceId": 10423464,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
